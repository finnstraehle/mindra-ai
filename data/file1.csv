NR,Rolle,Firma,Typ,Aussage,Cluster,Beschreibung,,,,,,,,
1,Chief Data Officer,Globaler Brauereikonzern,Collibra Success Story,"Yeah, so we use the enterprise data model, not necessarily the data models, but the enterprise data model as a way to represent in data the organizational key activities. So we built a data model, enterprise data model that was fit for purpose for the brewery business, realizing that in Heineken, we have different business models. So we built a data model, shall we say, for the main business model. (S.2)

Now, within the enterprise data model, we co-developed with architects and with business leaders and data owners in the business. We were looking to abstract at level of entities. We had about 300 data entities with the critical attributes, and we are abstracting the key
relationship among entities.

...And that was agnostic from any IT infrastructure. We were then able to map all our IT infrastructure to such entities and relationships and attributes. (S. 2) 

But essentially, we wanted to make sure that we were abstracting data at enterprise level. So we would have a conceptual model that was built by the architects. That conceptual enterprise data model would be mapped to a logical data model. And then that would allow all the different database structures to be mapped to that logical level. And then from an IT perspective, we would have an orchestration layer of different APIs. So essentially, you would have an application that would push data in a certain format. And then we could fetch data from other applications in the same format. So if you wish, it was effectively a translation layer that would enable processes across the different applications. (S. 3) 

And then we could fetch data from other applications in the same format. So if you wish, it was effectively a translation layer that would enable processes across the different applications. So this was part of a big re-engineering of the IT landscape of Heineken and a simplification of the IT landscape with essentially three levels in the landscape. One would be the ERPs at the center with one structure. Before, we had 35 ERPs with different structures. Then we had a set of critical business applications, again, certified from things like Microsoft Dynamics to capture consumer data to Blue Yonder for planning, etc. And then in the outer layer, you would have applications, so apps and all the e-commerce layer. So all the data flows were orchestrated through the orchestration layer. And the enterprise data model was the way to map all these data flows. So everyone was kind of translated at the logical level, but then mapped back. And then that mapping was in JSON files, etc","Use Case
","Use Case: Representation Key Activities
",,,,,,,,
1,Chief Data Officer,Globaler Brauereikonzern,Collibra Success Story,"Now, I stop here because the enterprise data model is something that you need depending on the architecture that you have. So for instance, if you were a company with only two business applications, shall we say that you have an ERP and a CRM, then in this case, I would say that a point-to-point integration is perfectly fine. So I think I would tend to think that you need an enterprise data model when you have a complex ecosystem of applications (S.3)",Implementierungsgrund,,,,,,,,,
1,Chief Data Officer,Globaler Brauereikonzern,Collibra Success Story,"...And maybe taking one step back, the reason why we did an enterprise data model in the first place was that Heineken had a very fragmented IT landscape. So we had over 3,500 different applications. And those applications, not necessarily were talking to each other. In many cases, they would be point-to-point integrations I'm not sure if you're familiar with IT, but it means that you have a direct integration of one application to the other. But collectively, if you also look at our aspirations in e-commerce, it was really difficult, for example, for customer data to travel across different applications. (S. 2-3)",Implementierungsgrund,,,,,,,,,
1,Chief Data Officer,Globaler Brauereikonzern,Collibra Success Story,"And usually, you have troubles in processes because one application doesn't understand the other, so you have a lot of defects. But that would be the case in which I think that I would use an enterprise data model and I would advise to use an enterprise data model. (S.3) So for us, in our case, we had what's called touchless processes. We wanted to reduce manual work because we had lots of people actually bringing data from one system to the other and we found that this was extremely inefficient. So it worked really well. (S.4) ",Implementierungsgrund,,,,,,,,,
1,Chief Data Officer,Globaler Brauereikonzern,Collibra Success Story,"The other thing that for me is clear is also the process layer. So an enterprise data model is very important for this process layer (S.4)

So for the enterprise data model, the main use case is touchless processes when you have a complex IT landscape. Yeah? So assuming, as we said, if we have an IT landscape that is comprising more than, shall we say, three applications, five, ten, tens of applications. And then when most of these applications pertain to the same entities, i.e. customer, product, then I think that enterprise data, and if you have an aspiration to have this almost
like real-time orchestration across the different application.  (S. 5) ",Use Case,Process Layer --> Reduktion touchless Processes ,,,,,,,,
1,Chief Data Officer,Globaler Brauereikonzern,Collibra Success Story,"So you need a catalog because first of all, you need to understand your data sources, where they're coming from. And that was the initial and original use case of Collibra. At the same time, as we were standardizing and doing this EDM, we took the opportunity to ensure that we would have a clear classification of all our data entities with all the definitions, all the business rules. And so that in Collibra, we will be able to move from the entities in the data model to the data sources underpinning those entities and create almost like this data store in which you can ask for data and you know where it's coming from. And then when we were in the process of also having data quality and observability linked to that process, so you would have an end-to-end view of your data sets. (S.4)",Use Case,"Use Case: Data Store
Funktionalität EDM: Verständnis der Datenherkunft durch EDM
Funktionalität EDC: Standardisierung durch Definitionen, Regeln",,,,,,,,
1,Chief Data Officer,Globaler Brauereikonzern,Collibra Success Story,"Because often in organization, you have the same KPI used in different ways with different meanings. So for instance, revenue is called revenue, but every department calculates in a different way. And that creates quite a lot of confusion. I think having in Collibra the KPI library with clear definitions, like this is the official definition and all the reports with revenue, they use the same methodology, the same data sets, the same methodology, for instance, in time, you know, when does the month start and end, etc. It was extremely useful because it started to compare things and make things much more comparable, whilst before each function would always have big discussions and disagreements on, okay, this is the right number, this is the wrong number, right? So I think I would say that was an incredible success in terms of having that catalog of KPIs. (S.4)",Use Case,"Use Case: KPI Katalog 
",,,,,,,,
1,Chief Data Officer,Globaler Brauereikonzern,Collibra Success Story,"And two, if you have structures of application, because you have an enterprise data model to which you can map any structure of application. So you become less reliant on a specific vendor. that aspiration of plug and play, so you want to be less dependent on specific structures of application, because you have an enterprise data model to which you can map any structure of application. So you become less reliant on a specific vendor. (S.5)",Use Case,"Weil das EDM dafür sorgt, dass man mehrere IT-Applikationen verbinden kann ist man weniger abhängig auf spezifische Verkäufer",,,,,,,,
1,Chief Data Officer,Globaler Brauereikonzern,Collibra Success Story," The second, sort of really important for us, was a business data owner would approve definition. So if you think of, okay, first of all, it would approve the enterprise data model, it would approve the definition, that would happen in Collibra. (S.6)

So it was a workflow management, whether we had the record of all the agreements and approvals that we had, but also it was the place in which we then approved changes, right? It's okay, the business leader has agreed to that change, so that would be almost like an audit in the system. We were then also using it to have a, if you wish, a more easier to understand version of the enterprise data model, because we had our version, but it was very like geeky, but there was also the business owners could see also the business, could see the enterprise data model through Collibra, could understand the definitions, could see the different relationships.","Use Case

","
Use Case: Workflow Management
",,,,,,,,
1,Chief Data Officer,Globaler Brauereikonzern,Collibra Success Story,"And then finally, we were then using it as a marketplace. So for instance, you have one specific entity, in this case we said customer, you can see all the golden sources of data entities, you could request access to that data source, if you were a data scientist, almost like as a store, that was integrated. So that was the way in which we used that. (S.6)",Use Case,Use Case: Market Place,,,,,,,,
10,Data Executive,Versicherungsfirma,Collibra Success Story,"And it was very, very hardbecause we were trying to do this in Excel. But it was very hard. One is really keeping it updated. Because, you know, as soon as you say one thing and then something changes and it's very hard to keep it updated. Collaborating was almost next to impossible with others. And then publishing it was problematic because you always had changes that are ongoing. So when I stumbled upon Collibra, I was like instantly, you know, my curiosity was, oh, this is a great thing that at least somebody is trying to put all of these pieces together. (S. 2) ",Implementierungsgrund,,,,,,,,,
10,Data Executive,Versicherungsfirma,Collibra Success Story,"And on top of that, they have a workflow. So not only that you can keep everything centrally, but you can also have, you know, different roles assigned so people can actually contribute and collaborate. And you have a workflow to step it through the process, right? (S.2)",Funktionalität Collibra,Zentrales Management des Workflows,,,,,,,,
10,Data Executive,Versicherungsfirma,Collibra Success Story,"So if they, for example, if they're using a report and that report gives them ability to make decisions, they should be in a position to know what is the data that they're basing their results on, how good the quality of the data is, who owns that data, what are the challenges with that data, if there are any. I feel like, you know, as a data governance team or data management team, we are responsible to make it as transparent to them as possible. And I found Collibra to be one great way to achieve that. (S.3)",Funktionalität Collibra,Schaffung von Transparenz,,,,,,,,
10,Data Executive,Versicherungsfirma,Collibra Success Story,"So my idea was to take, for example, a report and then, you know, work with the users of the report, understand, well, before the report was actually going live, understanding every piece of data that's coming into the report, what is the quality of that data? What does that report column mean? Who owns that? If I have any questions around that, who do I go? What system this data is coming from? That is the lineage? How old is this data? My point had been to establish a practice where every report before it can go live, I have all of these things answered and then certify that this has gone through the governance process. ",Use Case,Datenverständnis ,,,,,,,,
10,Data Executive,Versicherungsfirma,Collibra Success Story,"The second part I also wanted to do was to ensure that we have a mechanism for the users to raise the ability to raise tickets. So, for example, if they see something in the report that they don't agree with, they can question that and then it should go to the data quality team to resolve that. (S.3)",Use Case,Datenqualität,,,,,,,,
10,Data Executive,Versicherungsfirma,Collibra Success Story,"To me, the users don't need to know all the different sources and systems. But somehow the expectation is that they are the ones, because they are the owners, that they would know the quality of the data and any issues that are with that data. So just making them aware, giving them the transparency was my main goal. (S.3)",Use Case,Transparenz und Übersicht durch Collibra ,,,,,,,,
10,Data Executive,Versicherungsfirma,Collibra Success Story,"In my time, I didn't really explore, but you could also take it to another level where sometimes you might have a user group that looks for a data set and they can basically shop for the data set. They can say, okay, I want to get this data from this domain, this data from this domain, and I want it for my three months experiment. So you could provision that and all of those things come very naturally to Libra with this catalog experience. I haven't really used it, but I thought that would be pretty useful, especially for more data-savvy or tech-savvy groups that might be doing some research or they're doing some research around a specific hypothesis that they want to establish or they want to prove something out. (S.4)",Use Case,Use Case: Data Store ,,,,,,,,
10,Data Executive,Versicherungsfirma,Collibra Success Story,"So the basic capabilities, if I can explain to you in simple words, think of this as a library. So there's a catalog in the library, which basically lists all the books that are there. So think of Collibra as a catalog where you have accounts of all the data, which are synonymous to books here. And the data may have their, so we have all the metadata in the catalog, right? So you have, okay, this book is in this shelf and it talks about this and it was written by this author. It was published on this date. This is the ISV number. Similarly, Collibra has a catalog of all your data.

And there are two ways to do this. One way is to register in the sense like users can go manually register all the pieces of data and they can provide all the information --> glossary",Funktionalität Collibra,"Use Case: Business Glossary
Funktionalität Collibra: Manuelle Zuordnung der ""Bücher"" oder automatische Zuordnung der ""Bücher""",,,,,,,,
10,Data Executive,Versicherungsfirma,Collibra Success Story,"Second Way:  It's where basically you can govern all the, let's say a new book comes into the library. You can provide all the information about the book in the catalog so that every piece of information is captured. The second way to do this is if the system has a way to scan all the shelves and it will automatically populate the catalog and say, okay, on shelf 1.1 I have this and shelf 1.2 I have this. So the second part, which is what is catalog, is where you can actually have the ability to pull or scan everything and explore everything and then put it in the system, put it in the Collibra catalog. ",Funktionalität Collibra,,,,,,,,,
10,Data Executive,Versicherungsfirma,Collibra Success Story,"And then on top of that, you can provide some more manual, I guess, judgment over it. So some of it has like automated capability, so it can scan some of the data and say, okay, well, you know what? This data looks like personal and confidential to me, but I have like 70, 80% confidence on this. Somebody needs to manually go and validate that and it can learn from that. It's like, oh, this is not personal data because it's not a phone number or it's not an address or it's not somebody's name. (S.5)",Funktionalität Collibra,,,,,,,,,
10,Data Executive,Versicherungsfirma,Collibra Success Story,"So the tool provides the ability to catalog your enterprise data and it can group them in different domains. So I work in insurance, so there's a claims domain, there's an underwriting domain, there's different lines of business. So you can slice and dice in different ways. So every piece of data that is available at different, you can think of as like different genre for a library, you can cut it and slice it that way. So Collibra allows you to do all of those things, whether you want to do it manually. (S.5)",Funktionalität Collibra,Funktionalität Collibra: Daten katalogisieren,,,,,,,,
10,Data Executive,Versicherungsfirma,Collibra Success Story,"The first version that came out was if you were able to do it manually, like you can register everything. And then you had, you know, your different roles. So people are able to add on to like they can enrich the metadata with more information. (S.5)",Funktionalität Collibra,Funktionalität Collibra: Manuell Metadaten ergänzen,,,,,,,,
10,Data Executive,Versicherungsfirma,Collibra Success Story,"Also, when you have a new book or new data that comes in, you can send it through the workflow, which is basically send it to your data owner and steward committee and ask them who should own this piece. And is this the right name for it? If this is the right name, what is the correct definition? Because one of the challenges enterprises face is that the same thing is called multiple ways. So you want everybody to be speaking the same language. (S.5)",Funktionalität Collibra,Funktionalität Collibra: Workflow,,,,,,,,
10,Data Executive,Versicherungsfirma,Collibra Success Story,"So what Collibra allows you to do is you can ensure that something that is for, let's say, customer, everybody understands what customer means because it's defined. You have an owner because, you know, in a complex organization, customer could be very different people. (S.6)",Funktionalität Collibra,Nutzen Collibra: Klare Verantwortlichkeiten und Definitionen,,,,,,,,
10,Data Executive,Versicherungsfirma,Collibra Success Story,"So another thing is to ensure, you know, in different communities, you could have like different terminology. How do you either keep it federated or you can departmentalize it? However you want to implement it, you have the ability to do that. (S.6) And the other challenges users face sometimes is that they might have two different reports reporting different data with different numbers. Well, same data may be different numbers because they may have different criteria and they may be calling something different. So that's a common problem. And one way to avoid that is to use a common terminology and using that terminology, ensure that every report or every dashboard has a very clear understanding of what are they reporting. What does it mean? And it should not conflict with something else that's already there. So Collibra allows you to do that. ",Funktionalität Collibra,Use Case: gleiche Begriffe,,,,,,,,
10,Data Executive,Versicherungsfirma,Collibra Success Story,"And then with some integration with other systems, you could actually achieve a lot of automation in this regard. So you have the ability to also link your business metadata to technical metadata. So then you have the ability to trace the complete lineage and understand how this data has come from source A all the way to this report and along the way all the different hops that it has gone through. (S.6)",Funktionalität Collibra,Use Case: Lineage,,,,,,,,
10,Data Executive,Versicherungsfirma,Collibra Success Story,"And also you have the ability to look at the status or the quality of the data. If you are measuring the quality, if you have the specific rules around. So, for example, you want to make sure that the business rules that you define. So, for example, if there's a date and that date cannot be a future date and this system has future dates. So now you know that there are some issues with this data. What percent of data have that issues? What is acceptable? What is not acceptable? (S.6-7)

So you can define your whole data quality strategy around it. But at the end of it, as a data management professional, you need to combine all of that information for a consumer in a format or in a way that is consumable for the owner. So they underst",Funktionalität Collibra,"Funktionalität:  Business Rules
Use Case: Qualitäts Strategie rund um den EDM bauen",,,,,,,,
10,Data Executive,Versicherungsfirma,Collibra Success Story,"But this has like the, you know, there's what I call it, there's like the offense and defense, right? So the defense part is the regulatory part where you need to have these in place so that you can show that your company is compliant with this. You're protecting personal information. You're ensuring that the right, you know, people have access to the right data. But on the other side, the efficiency part is the offense part, right? So if you wanted to be competitive, you want, you know, quick response. You want people to be able to self-serve. (S.7-8)",Funktionalität EDM und EDC,"Offense (Effizienzsteigerung ) 
Defense (Regulatorischer Schutz) ",,,,,,,,
10,Data Executive,Versicherungsfirma,Collibra Success Story,"They don't have to be asking like five different departments to answer one simple thing that they can do themselves. So self-serving is to me is very important. With tools like Collibra, that kind of gives the ability to do that. (S.8)",Use Case,Use Case: Self-Serving,,,,,,,,
10,Data Executive,Versicherungsfirma,Collibra Success Story,"It's become important that we can show we know where our enterprise data lives. And we understand where we have a confidential and secret data. How are we protecting it? Who has access to it? All of this kind of ties together, right? That's a defensive part, which is basically we need to have that for regulation and regulation compliance (S.8)",Use Case,,,,,,,,,
10,Data Executive,Versicherungsfirma,Collibra Success Story,"So as I was explaining, there's some data quality issues. If you have the ability to know what the root cause is, you're able to find that and solve that quickly, as opposed to figuring out that some report had something wrong. And then it's a more reactive approach. (S.8)",Use Case,Nutzen EDC/EDM: Proktive Gestaltung der Datenqualitätsprüfung,,,,,,,,
11,Experte,Collibra,EDM / EDC Anbieter,"Was sind typische Use Cases? Auf der einen Seite geht es darum, ganz einfach mal aus der technischen Sicht zu beschreiben, was habe ich da für Daten? (S.4)",Use Case,Übersicht Daten,,,,,,,,
11,Experte,Collibra,EDM / EDC Anbieter,"Frage: Kann man die Use Cases vom Katalog und von Collibra differenzieren? Kannst du die wichtigsten Use Cases mal beschreiben?
Antwort: Ja, Jein, das ist natürlich genau das Wichtige. Man versucht, dass man in diesem Thema klar umrissene Use Cases gegeneinander abgrenzt, einfach damit man auch etwas hat, worüber man dediziert sprechen kann. Und unten drunter sind die aber alle miteinander vernetzt. Weil unten drunter ist quasi mein Boost an Daten und dann setze ich ja auf diesen Boost an Daten verschiedene Use Cases drauf. (S.4)",Funktionalität Collibra,Use Cases (Funktionen)  bauen aufeinander auf,,,,,,,,
11,Experte,Collibra,EDM / EDC Anbieter,"[Mit Collibra] Technische Datenmodelle reinholen, das kann ich hochautomatisiert machen (S.4)",Funktionalität Collibra,Use Case: Integration Technische Datenmodelle,,,,,,,,
11,Experte,Collibra,EDM / EDC Anbieter,"Dann, was ich dann auch typischerweise machen will, ist, dass ich eine Art Terminologie für das Unternehmen definiere. Man nennt das Business Glossary in der Regel. Das heißt also einfach aufschreiben, was ist Umsatz, was ist Kunde und so weiter. Und dann wird es natürlich spannend, dass ich das miteinander vernetzt, dass ich quasi einen Semantik- Layer über meine technischen Daten lege. Dass ich also sage, dieses Feld hier, was XYZ heißt, beschreibt eigentlich die Adresse eines Kunden. Weil das Feld in der Datenbank muss ja gar nicht adressig des Kunden heißen. Das kann ja eben auch wirklich was Kryptisches sein. Das heißt, diese Verständlichkeit für meine Daten zu schaffen, das ist ein ganz wichtiger Use Case.",Funktionalität Collibra,Business Glossary + Verknüpfung technische Daten ,,,,,,,,
11,Experte,Collibra,EDM / EDC Anbieter,Technische Lineage. Wie laufen meine Daten durchs Unternehmen? Wie wird das mit ETL-Tools wirklich so von einer Datenbank in die andere reingeschoben? Wie wird das mit ETL-Tools wirklich so von einer Datenbank in die andere reingeschoben? (S.4),Funktionalität Collibra,Use Case: Technische Lineage,,,,,,,,
11,Experte,Collibra,EDM / EDC Anbieter,"Dann ein weiterer Use Case ist, diese ganzen Informationen, die ja technisch sind, Metadaten und Lineage, zu abstrahieren, dass das auch vielleicht ein, naja, öffentlicher Vorstand, aber halt ein businessorientierter User versteht. Der einfach jetzt wissen will, ich habe da einen Report in der Hand, Sales Report XY. Und woher kommen meine Daten? Kann ich denen vertrauen? Kommen die daher, wo ich sage, die haben auch eine Ahnung davon? Das heißt also, so eine Business-Abstraktion da reinzubringen in diese technischen Themen. (S.4)",Funktionalität Collibra,Use Case: Business Abstraktion Lineage,,,,,,,,
11,Experte,Collibra,EDM / EDC Anbieter,"Dann ein typischer Use Case ist auch, relativ neu jetzt, auch mit einem neuen Label versehen, geben tut es das natürlich schon immer, sind Datenprodukte. Das heißt also, dass ich technische Datenartefakte so zusammenhacke, dass sie eben von jedem gefunden und auch verwendet werden können. (S.4-5)
Das heißt, dass ich mal bei einem weiteren Use Case, Data Discovery nennt man das gerne, wo finde ich denn überhaupt Daten? Da sind wir natürlich vor allem, jetzt habe ich mal technisch gesprochen, brauche ich da eine Suche, die gut ist, aber halt dann auch eben die, praktisch wieder diese Verlinkung mit diesem semantischen Layer, Business Glossary und so weiter, damit ich mein Bild machen kann. Ich habe jetzt da irgendwie fünf Datenpakete zur Auswahl. Welches ist es, das ich wirklich benutzen will? (S.5)
",Funktionalität Collibra,Use Case: Datenprodukte + Data Discovery ,,,,,,,,
11,Experte,Collibra,EDM / EDC Anbieter,"Dann Automatisierung von Data Governance Prozessen, auch was ganz, ganz Wichtiges. Wenn ich zum Beispiel Datenzugriff beantrage, wenn ich, soll ich das zu tief oder passt das sowas? Wenn ich also zum Beispiel Datenzugriffe beantragen will oder wenn ich, was ist noch ein typischer Governance Prozess? Fehler melden bei Daten ist natürlich auch was, ein Klassiker. Oder zum Beispiel, wenn ich auch im Modell Erweiterungen beantrage, ich will neue Felder haben oder sowas. Das sind alles so typische Governance Prozesse. Das heißt, und technisch gesprochen, Collibra und halt auch andere Tools, ich rede halt jetzt von Collibra, aber es sind andere Tools dann ähnlich, heißt das Workflow Automatisierung.

Dass du also die Möglichkeit hast, hier Workflows, Prozesse in Workflows zu gießen, hinten dran dann Rollen hast und dann eben je nachdem... Also, dass ich im Prinzip, wenn ich eine Zehn-Mann-Bude habe, dann kann ich natürlich einfach sagen, der macht das, der macht das, der macht das. Das haut natürlich nicht hin bei einem Unternehmen mit 500.000 Leuten. Das heißt, da brauche ich Rollen-Konzepte, wo die Maschine dann automatisch weiß, wenn ich jetzt diese Daten anfrage, dann muss ich das an den routen. Wenn ich andere Daten anfrage, dann muss ich das an den anderen routen....Also, das heißt also, diese Governance-Prozesse zu automatisieren und dabei aber all diese Komplexität natürlich zu beachten. (S.5)","Use Case

","Use Case: Automatisierung von Governance-Prozessen / Workflow-Management
",,,,,,,,
11,Experte,Collibra,EDM / EDC Anbieter,"Mit Daten muss ich bestimmte Regularien einhalten, wie zum Beispiel EU-AI-Act, EU-Data-Act, solche Dinge. Auch ein typisches Ding, dass ich Policies manage für die Daten, dass ich die da dran hängen kann. (S.6)",Use Case,"Use Case: Regulatorik 
",,,,,,,,
11,Experte,Collibra,EDM / EDC Anbieter,"AI-Governance wird ein großes Thema, wo ich dann auch tracken muss, welche Daten fliegen denn eigentlich rein in meine AI-Use-Cases. Da haben wir dann häufig auch mit unstrukturierten Daten zu tun, weil das der besondere Power von AI-Modellen ist, dass ich da jetzt auch PDF und weiß da drüber, was alles reinkippen kann, was bestimmte technische Herausforderungen wiederum bringt, wo ich dann auch wiederum mit AI-Techniken sowas automatisiert evaluieren kann. Was ist denn da drin in so einem PDF? Und dann eben immer die Frage, sind persönliche Daten drin, sind schützenswerte Daten drin, solche Dinge (S.6)","Use Case
",Use Case: AI Governance,,,,,,,,
11,Experte,Collibra,EDM / EDC Anbieter,"Funktionalität: Das andere ist dann, dass ich eigentlich Datenqualität messe. Das tue ich typischerweise mit Regeln. Das heißt also irgendwie in SQL oder sowas gescriptete Regeln, die halt einfach aus meinen Datenbanken dann prüfen, ist da da was drinnen. So die primitivste Regel, leer oder nicht leer. Wertebereiche sowas, auch noch sehr primitiv, aber natürlich können Regeln auch komplex sein. Wenn in der Tabelle in dem Feld das und in der das, dann sollte da das und so weiter. Also das ist aber immer noch statisch dann natürlich auch, dass sich Daten über die Zeit in eine komische Richtung ändern. Sowas sollte eine Maschine auch erkennen. 

Use Case: Das kann dann entweder ein Datenproblem sein, oder ich habe das mal mit einem Fahrzeughersteller gehabt, die erkennen daran dann zum Beispiel auch Produktionsprobleme, wenn auf einmal ganz komische Daten kommen. Das heißt also, das ist dann nicht mehr ein reines Datenproblem unter Umständen. Dabei ist es dann nicht, ist der Sensor kaputt, oder kommen verbeulte Autos vom Band. Solche Dinge. Und da haben wir natürlich dann die Challenge. Jetzt kann ich natürlich irgendwie, sage ich mal, für ein Feld das immer ganz stark mit Regeln basierend machen, aber jetzt nehmen wir mal so ein Data Lake, wo hier Terabyte von Daten irgendwie reingekippt wurden. Oder auch ich nehme mir an, für jedes Feld irgendwelche Validierungsregeln zu überlegen, weil da mache ich irgendwie mit meinem Unternehmen nichts anderes mehr. Das ist auch immer so eine Challenge bei diesen ganzen Themen. Wie gut will ich sein? Oder wo ist der optimale Punkt? Perfekte Daten sind unbezahlbar, bringt nichts. Ich muss den Sweetspot haben. Wie viel investiere ich in meine Daten? Qualität, Management und so weiter. Ohne, dass mir die Kosten davonlaufen. 

Und da gibt es dann natürlich eben, das haben wir dann eben auch in unserem DQ-Tool, andere machen das auch ähnlich, gibt es dann die Möglichkeit, dass ich so Regeln automatisch generiere, so mit Maschinen-Learning-Ansatz, dass ich da einfach ein Data Lake dranstöpsel und dann versucht die Maschine, sinnvolle Regeln, hunderttausende von Regeln, selbst zu produzieren, die ich dann halt fine-tunen kann. Und dann schließt sich ja wieder der Regelkreis. Das eine sind immer diese statischen Betrachtungen. (S.6-7)

nn irgendwelche Schwellwerte überschritten sind bei der Datenqualität oder bei Datenqualitätsproblemen, dass dann auch Leute automatisch angetriggert werden, dass die was tun. Und da ist natürlich auch die Automatisierung wichtig, weil da kann ich ja nicht das Unternehmen laufen, wem gehört das Datenfeld. Das muss dann auch wieder automatisiert erkennbar sein. Das heißt, dass ich so was wie Data Owner, Data Steward und so weiter im System hinterlege. Als Rollen wieder, nicht als Mensch natürlich. Sonst habe ich ein Problem, wenn der das Unternehmen verlässt",Use Case,Use Case: Regeln für höhere Datenqualität (Automatisiert) ,,,,,,,,
11,Experte,Collibra,EDM / EDC Anbieter,"manche sehen darunter natürlich auch noch den Datenzugriff, das heißt, dass ich tatsächlich auch, wenn einer Daten braucht, den physischen Zugriff, den Durchgriff auf die Daten steuere. Und da habe ich natürlich auch wieder so ein bisschen so ein bisschen, also auf der einen Seite will ich das ja ein Stück weit auch automatisieren, auf der anderen Seite habe ich da natürlich auch die Challenge, jeder darf ja vielleicht Daten ein bisschen anders sehen. Also der eine, der darf die Daten sehen so wie sie sind, der andere darf sie nur maskiert sehen, der dritte darf sie gar nicht sehen. Ist also auch noch mal so ein Thema für sich, an und für sich, die ganze Datenzugriffssteuerung. Und dann natürlich auch, ja, das ganze Thema gesetzliche Einhaltung gesetzlicher Vorgaben, Data Privacy und so (S.8)",Use Case,Use Case: Data Privacy,,,,,,,,
11,Experte,Collibra,EDM / EDC Anbieter,"Und jetzt vielleicht so ein bisschen, naja, wir haben es mal so gehabt, wie finde ich Daten, da hat man oft so dieses Schlagwort noch, Data Marketplace, das ist so das, was derzeit in aller Munde ist, um halt eben Daten schön konsumierbar zur Verfügung zu stellen. Das könnte man jetzt auch, aber das ist alles nicht so ganz drin scharf, ja, das ist halt auch, da gibt es immer Überlappungen zwischen den Themen. (S.8)",Use Case,Use Case: Data Marketplace,,,,,,,,
11,Experte,Collibra,EDM / EDC Anbieter,"Dann, technische Lineage ist durchaus auch hier relevant, weil wenn ich sage, das sind so indirekte Effekte dann eher. Wenn ich also weiß, wo meine Daten herkommen und wie sie zusammenlaufen und auch noch Transparenz über diese Transformationsregeln habe, dann kann ich natürlich auch besser die Datenqualität managen, als wenn das alles hier Blackbox ist und ich darauf vertrauen muss, dass die Daten in irgendeiner Tabelle richtig sind. (S.13)",Funktionalität EDC,"Besseres Verständnis über Daten, Lineage, Qualität",,,,,,,,
11,Experte,Collibra,EDM / EDC Anbieter,"Dann, was man ja auch machen kann, ist, man kann ja auch zum Beispiel dann auch den ganzen Business-Kontext mit abbilden. Welche Prozesse produzieren ein Datenset? Welche Prozesse konsumieren ein Datenset? In welcher Unternehmens-Business-Domain sind die Daten zu Hause? Auch das kann mir helfen, festzustellen, ob jetzt Daten verlässlich sind oder nicht, ohne dass ich jetzt reinschaue. Vorher habe ich einfach nur ein Datenset vor mir, wo ich nichts weiß. Das denke ich sind so die Aspekte, wenn es um Datenfehler Vermeidung geht. (S.13)",Funktionalität Collibra,Kontextualisieren von Daten,,,,,,,,
11,Experte,Collibra,EDM / EDC Anbieter,"Plus natürlich dann auch ein Ding, da sind wir wieder bei der Prozessautomatisierung, dass ich Datenfehler melden kann. In den meisten Unternehmen, wenn ich jetzt einfach irgendwo ein Datenproblem habe, habe ich doch keine Ahnung, wem ich das sagen soll. Aber wenn hintendran eben dann im Katalog diese ganzen Ownerships hinterlegt sind, und dann habe ich vielleicht eben so eine Report-on-Issue-Funktionalität, dann drücke ich da drauf und sage, schau dir mal das an, irgendwas stimmt hier nicht. (S.13)",Use Case,"Use Case: Automatisierung Workflow ""Report-on-Issue""",,,,,,,,
11,Experte,Collibra,EDM / EDC Anbieter,"Also wir reden über verschiedene Systeme, weil da muss man genau spezifisch sein. Wir reden nicht darüber, dass derselbe Kunde in einer Tabelle dreimal steht, das ist ja ein Duplikat innerhalb der Tabelle, das kann natürlich ein Datenqualitäts-Tool dann abfackeln. Das andere ist natürlich deutlich komplexer. Was hier möglich ist, ich habe hier zwei Datenbereiche, die vielleicht gar nichts von einer wissen und die pflegen dieselben Daten. Idealerweise lege ich ja einen logischen Layer, also ein logisches Datenmodell im Sinne von Enterprise Data Model, lege ich über die verschiedenen Bereiche und dann kann ich natürlich meine Daten, meine Tabellen darauf mappen. Und wenn ich natürlich dann irgendwo einen logischen Layer habe, wo ich eben Kundendaten speichere, als Beispiel, und dann habe ich in zwei verschiedenen Bereichen festgestellt, dass hier die dort Verantwortlichen wiederum ihre Daten auf dasselbe logische oder konzeptuelle Objekt mappen, dann habe ich, dann kann ich das erkennen. 

Ich weiß auch nicht, ob es da irgendwie spezialisierte Tools gibt, die das schon automatisieren oder nicht. Aber das ist sag ich mal so eine Möglichkeit, die ich dann habe. Ich kann natürlich dann auch ich meine so ein Business Glossary ist ja auch eine Art konzeptueller Layer. Auch da wiederum, wenn verschiedene Datenbanken ihre Felder mit denselben Einträgen im Business Glossary verlinken, dann kann ich ja sowas auch abfragen. Das kann ich ja dann feststellen. Einfacher ist es natürlich, sobald ich in einem Data Lake bin. Dann habe ich halt eine Datenbasis vor mir und dann kann ich da so Tools drüberlaufen lassen, die sowas eher mal erkennen. Wenn ich jetzt, sag ich mal, sehr weit entfernt im Unternehmen ähnliche Daten habe, muss man einfach sagen, es ist schwierig. Wenn da nicht sehr extrem konzeptuell Daten modelliert werden, was die wenigsten tun, also theoretisch geht das alle, ist kein Thema. (S.14)",Funktionalität EDM und EDC,EDM erkennt Doppelungen in den Daten,,,,,,,,
11,Experte,Collibra,EDM / EDC Anbieter,"Täglich irgendwo Datenbreaches. Und wenn ich dann eben auch ganz schnell bin, weil ich die Prozesse automatisiert habe, sowas wieder einzufangen, dann kann ich, also erstens kann ich die Eingriffswahrscheinlichkeit von Daten, von Privacy Security Problemen reduzieren. Und zweitens kann ich auch den Impact reduzieren, wenn es passiert.",Use Case,Schnellere reaktion auf Daten Breaches,,,,,,,,
11,Experte,Collibra,EDM / EDC Anbieter,"Und was dann noch dazu kommt, dann hast du noch so einen Second-Order-Effekt drinnen. Wenn die Data Scientists eben mit weniger Aufwand und schneller sind, Dinge rauszuhauen, dann können die auch mehr machen. Du bist früher am Markt damit und du kannst auch viel mehr tun",Use Case,Schnellere Reaktion auf den Markt durch Schaffung von mehr Kapazitäten,,,,,,,,
3,Experte,Collibra,EDM / EDC Anbieter,"Like, one of the use cases I was recently looking at was something simple like, finding what something means, right? So a lot of customers have what something means in a spreadsheet. So this could mean customer, right? If I go and ask you, how many customers do we have? And if you go and ask somebody else, how many customers do you have? And if you say it's a hundred and if that person says it's 300, right, we have a fundamental difference between the number of customers. Number of customers should be something that, you know, should be the same, right? It's because both of you are right or wrong because the simply that the definition you're using to measure what a customer is might be different, right? And that is because of the way that your business is functioning, your business line of business is functioning. So in order to minimize this kind of problems, you can have a simple thing of definitions, right? It's a simple use case where you have a glossary, right? You have a glossary where you say, this is what we mean by customer. This is what we mean by address. This is what we mean by whatever, right? (S.7)",Use Case,Use Case: Business Glossary,,,,,,,,
3,Experte,Collibra,EDM / EDC Anbieter,"And once you have those [Definitions], then you can start linking them to your data when you have it. So imagine that as a simple example, imagine customer name, right? This is a definition, but in the database, you might have cost F name, cost L name or whatever it is, right? So it's two fields that is representing customer name. So you can simply link those, at least in Collibra you can, where you can link them and say, okay, so these two fields are linked to customer name. (S.7)",Funktionalität Collibra,"Funktionalität Collibra: Technisches ""Definieren"" von festgelegten Begriffen (Kunde stellt sich aus folgenden Feldern zusammen)",,,,,,,,
3,Experte,Collibra,EDM / EDC Anbieter,"And another one that is also very, very quick, quick is a lot of customers will have code values and code sets, right? Especially banking customers, financial, sorry, people like say, healthcare customers, they will have code values and code sets. Now, what that means is that those code values and codes have to be governed in some way, right? So imagine that simple thing like UK versus GB, right? Great Britain. They're different ducks, right? In terms of entities, they're different things. And then all of this time, for whatever reason you needed, you were using GB, but now you have to change it to UK. Who makes that decision? Somebody makes that decision. And then you need to know where this UK is being used in which tables. Now you already ingested the tables.  You can start to build those linkages to say, okay, this table has these columns that talks about country codes and country codes are linked to this code set, right? And whatever those values, if there's a change in Collibra, we at least have, if there's a change, you can notify the, the product, technical stewards or whoever to say, hey, there's a new change that happened in this code set. Make sure that your source systems are updated or whatever. (S. 9)",Funktionalität Collibra,"Funktionalität Collibra: Durch die Verlinkung und die technische ""Definition"" von festgelegten Begriffen (Country Codes) können die dafür verantwortlichen Stewards bei Änderungen benachrichtigt werden und aufgefordert werden,  diese Data Sets (Alle Country Codes) zu updaten. (Workflow)",,,,,,,,
3,Experte,Collibra,EDM / EDC Anbieter,"[Durch Verlinkung der Bestandteile mit dem Überbegriff] I'll give you another example, a very simple example that I was working with a bank and they had about, I think, 10,000 or 11,000, like a lot of code sets. Now they were getting this from Experian, they were getting it from different credit organizations and other things, right? But what they found after they brought that into Collibra was that some of those were almost the same, but they were paid separately. They were paying separately to Experian or whatever it is, right? And some of them are very similar with very small differences, right? So what they did was that they managed to bring down the number of code values and code sets from 11,000 to, I think, to about 7,000 or 8,000. So that's a huge, that's a huge saving because they're not paying anymore for whatever that was. (S.9)",Use Case,Kostenersparnis durch weniger Cloud-Speicher-Ausgaben,,,,,,,,
12,Chief Operations Officer,Handelsunternehmen,Externe Firma,"So wie ich jetzt das Modeling verstehe, ist das eher ein Top-Down-Ansatz, wo man die Zusammenhänge der Daten darstellen möchte und so auch in einen Kontext setzen möchte (S.3)",Funktionalität EDM,Darstellung der Zusammenhänge und des Kontexts der Daten,,,,,,,,
12,Chief Operations Officer,Handelsunternehmen,Externe Firma,"Und beim Cataloging ist es eher so, dass man es grundsätzlich mal auflistet und bottom-up zur Verfügung stellt und dann der User eigentlich rauspickt, was er braucht. (S. 4)",Funktionalität EDC,Bereitstellung der Daten,,,,,,,,
12,Chief Operations Officer,Handelsunternehmen,Externe Firma,"Ich glaube, das ist ein Use Case, wo man die Potenziale sieht, die aus Daten kommen, die eben darüber hinausgehen, was Menschen selbst 80-20 optimieren können. Bei uns jetzt bei XY ist auch wieder eine Robotik im Einsatz und die Robotik muss verstehen können, welche Artikel kann ich überhaupt und wenn ja, wie greifen. Und jetzt ist es ja so, dass wir auf die 300.000 Artikel, die wir im Lager haben, jedes Jahr etwa 70.000 neue haben. Es ist unmöglich, diese Datenmenge zu pflegen, also muss ich da mit künstlicher Intelligenz, mit Lernalgorithmen drangehen. Da komme ich vielleicht sogar in einen Bereich, wo ich die Daten dahinter gar nicht verstehe, also wo einfach die KI das auflöst und ich müsste via Reverse Engineering dann wieder herausfinden, was sind jetzt die Attribute, die zu dem Resultat geführt haben. Aber das ist auch etwas, kein Mensch könnte das tun, aber mit Daten kann ich das relativ einfach machen. (S.7)","Use Case
",AI ermöglicht Optimierung der letzten 20%,,,,,,,,
2,IT Projektleiter,Detailhandel,Externe Firma,"Ähm, wir haben bei uns, also das Thema Enterprise Data Model ist aus der Architektur getrieben. Wir sind da, haben einen Schulterschluss auch mit dem Unternehmen XY gemacht. Ähm, der Haupttreiber ursprünglich, jetzt bei uns, war wirklich die Kommunikation zwischen den Systemen, so quasi Mittelware Layer mässig, halt API first zu, so sieht der Point-to-Point-Integrationen zu verhindern und halt wie so einen abstrakten Kommunikationslayer im Sinne Mittelware Layer zu etablieren. Ähm, und da halt wirklich mit dem Data Model, also wir haben es immer versucht so intern zu erklären, oder bei Point-to-Point hast du quasi, ja der spricht Deutsch, der Französisch, das heisst du musst Deutsch nach Französisch übersetzen, dann Französisch nach Italienisch. Und mit dem Enterprise Data Model etablieren wir Englisch als zentrale Sprache, damit die Systeme austauschen können untereinander. (S. 2)",Funktionalität EDM,EDM Systemintegration,,,,,,,,
2,IT Projektleiter,Detailhandel,Externe Firma,"Unternehmen XY hat als Data Platform GCP im Einsatz, und die haben wirklich in Collibra angefangen, alle Objekte, also die Metadaten aus dieser GCP-Umgebung primär, quasi automatisch anzubinden, und dann halt mit diesen Data Rollen, diese Data Governance Rollen, also Data Owner, also wer definiert die Daten, wer ist verantwortlich dafür, wer ist der technische Owner, halt diese ganzen Rollen etabliert, und haben danach das auch noch ein bisschen ausgeweitet, und zum Beispiel eingekaufte Daten darin beschrieben, da war der Case vor allem, dass wir jetzt in der Gruppe für Daten nicht doppelt bezahlen, sondern die meisten eingekauften Daten quasi einmal gekauft, einmal beschrieben, einmal einen Owner spezifiziert, und dann zentral zur Verfügung gestellt, oder? (S.3)

Und jetzt konkret bei EDM (Es wird zwar EDM gesagt aber wir glauben es wird EDC gemeint) haben wir natürlich diese Data-Domains bei uns erarbeitet und auch für jede Data-Domain auch einen Owner. Und da haben wir jetzt Prozesse etabliert mit diesem Domain-Owner, weil bei uns gab es ein GL-Entscheid, dass die Datenqualität gehört zu diesem Lead-Data-Owner. D.h. die sind verantwortlich für die Datenqualität in ihrer Domain. Da gibt es eine Domain Artikelstammdaten und es gibt eine Domain Filialstammdaten z.B. Und da quasi wir sehen jetzt, wenn irgendwo ein Prozess blockiert ist, weil ich sage jetzt bei einem Artikel stimmt der Preis nicht und so da gibt es also da sehen wir die Anzahl Tickets, die kommen und die sind theoretisch jetzt quantifizierbar.(S.8)","Use Case

","Use Case: Dokumentation bestehender Assets
",,,,,,,,
2,IT Projektleiter,Detailhandel,Externe Firma,"Also wenn ich jetzt hier unseren Reifegrad, den Komplettheitsgrad beschreiben müsste, dann sind wir bei uns vielleicht bei 30%. Und beim Unternehmen XY im Sinne von Data-Katalog wahrscheinlich schon so im Bereich 70-80%. Es gibt auch so Domain-Scorecards, wo eigentlich pro Data-Domain so Scorecards existieren, wo mit den Lead Data Owners ein Interview-Prozess gemacht wird, um herauszufinden, was ist der Score dieses Data Assets hinsichtlich Quality-Control, Ownership und gewissen Dimensionen, die abgefragt werden. (S.3)",Funktionalität EDM und EDC,Funktionalität EDM/EDC: Data Domain-Scorecards zeigen den Reifegrad der Datenqualität,,,,,,,,
2,IT Projektleiter,Detailhandel,Externe Firma,"EDM: Beim EDM, glaube ich, wird der Value erst über Zeit spürbar, wenn man dann Änderungen in der Systemarchitektur hat oder wenn man dann quasi ein System austauscht und man nicht mehr die zehn Umsysteme wegen Spaghetti- oder Point-to-Point-Integrationen anfassen muss, sondern sich einfach nur um diese eine Schnittstelle, sei es ein Consumer oder Producer, kümmern muss. Und diesen Wert, den wirst du erst über Application Lifecycle Zeit von drei bis fünf Jahren spüren, der ist jetzt heute unmittelbar noch nicht so spürbar. Den müssen wir auch immer wieder verkaufen im Sinne von Flexibilität und Agilität der Systemarchitektur. Vielleicht Schemadifferenzen. Umsatz ist ziemlich relevant bei einem Retailer. Da haben wir viele Abhängigkeiten. Das hätte zu Problemen geführt, dass wir diese Schema-Änderungen in x Umsystemen hätten nachziehen müssen. Je nachdem, wie oft oder wie schnell. Dann hätten sie das merchen müssen (S.4)",Funktionalität EDM,Abschaffung von Point-to-Point Systemwechseln,,,,,,,,
2,IT Projektleiter,Detailhandel,Externe Firma,"EDC: Bei Katalog ... Da hat das Unternehmen XY einen Push gemacht, möglichst viele Data-Assets zu identifizieren, den entsprechenden Owner zu identifizieren, das zu beschreiben. Da hinsichtlich Mehrwert. Man hat herausgefunden, dass ein und dieselben Marktforschungsdaten von zwei Derpartments eingekauft wurden. So haben wir hier schon. ""Du zahlst auch? Wir zahlen auch."" (S.5)",Use Case,Schaffung von Transparenz und Überblick (keine Duplikate),,,,,,,,
2,IT Projektleiter,Detailhandel,Externe Firma,"Low-Hanging-Fruits wie doppelter Daten-Einkauf entdeckt man nur, wenn man einmal die Daten-Assets katalogisiert hat - man braucht aber nicht unbedingt Collibra (S.5)",Use Case,Schaffung von Transparenz und Überblick (keine Duplikate),,,,,,,,
2,IT Projektleiter,Detailhandel,Externe Firma,"EDC: Aber ich vergleiche es immer so, also mein Katalog ist beim Namen schon inhärent mit drin, das ist wie so, du gehst in die Bibliothek und dann siehst du quasi das Inhaltsverzeichnis, was ist in dieser Bibliothek mit drin. Es ist mehr ein Beschrieb deiner Assets und der Verantwortlichkeiten darüber (S.7)",Funktionalität EDC,Schaffung eines Inhaltsverzeichnisses / Überblick,,,,,,,,
2,IT Projektleiter,Detailhandel,Externe Firma,"EDM: Das Data-Model ist für mich dann eher als ob du vorschreiben würdest, wie diese Bücher gebunden sein müssen, damit du möglichst viele Bücher in die Bibliothek reinbringst. Das Data-Model ist mehr so diese Data-Producer, also wie bringe ich Data-Producer und Consumer optimal zusammen (S.7)",Funktionalität EDM,Standardisierung und Strukturierung von Datenmodellen,,,,,,,,
13,Experte,Starburst,EDM / EDC Anbieter,"Collibra really creates a platform to scale governance from inventory and what you have from a tech perspective, where your data is stored, and really assigning business context to it, meaning like what it actually is, and putting mechanisms around it in order to focus more on the things that are important and less on the things that are not important, and making sure that the important data, especially the important data, really falls through on things that are both required for businesses based on their industry, and also what's good practice in terms of where they will see benefits from it (S.2)",Funktionalität Collibra,Skalierbare Data Governance durch Zuweisung von Business-Kontext und Priorisierung wichtiger Daten,,,,,,,,
13,Experte,Starburst,EDM / EDC Anbieter,"That's right. That's the core proposition of data federation, is the term, is getting access to the data regardless of where it is stored, and there are multiple design patterns in order to achieve that. But yes, you buy a business, you sell a business, you still have to get across it, and most large organizations have fragmented teams, technologies, and also data silos. (S.2)",Use Case,Data Federation (Zugriffsrechte),,,,,,,,
14,Berater,Globale Beratungsfirma,Beratung,"And for that, from what we see in the market, at least in terms of banks, they're fairly mature in terms of having a data catalog or something similar in place. And also something that might be of interest to you is that there's three different things in that regard. So, there's the business glossary that contains all of your business terms on a business context level. So, let's say a customer is a business term. A customer is a client of the bank or it could be a client. Then there's the data, let's say a client is a business term contained within the business glossary. So, you have that one list of business terms. For example, a client is a person who transacts with the bank.

And then you have a data catalog, which represents a data element, which is a collection of data attributes. So, for example, the data catalog version of a client will be a customer. A customer is a specific person who takes out a loan or invests with the bank or has a checking account with the bank. And then that data catalog contains all of the data attributes underlying that particular element, which you can find in the data dictionary.

So, there's three things. There's a data dictionary, the data catalog, and the business term. And they're all linked. The data catalog is sort of in the middle, helps you go from the highest level of a business term to seeing which sort of definition or package contains further details and more granularity. And the most granularity is contained within the data dictionary. So, let's say a client in the business term represents a data element in the data catalog, which could be a customer with its own definition and its own metadata. And then that customer is basically a representative package of a bunch of different things that a customer is made up of. So, a customer can be made up of first name, last name, address, email ID. All of these things will be data attributes in the data dictionary linked to a single data element in the data catalog. (S.4-5)",Use Case,"Use Case: Business Glossary
Funktionalität EDM/EDC:
Business Glossary -> Geschäftsbegriffe (Enterprise-Ebene)
Data Catalog -> Konkrete Datenobjekte (Sammlung von Attributen des Geschäftsbegriffes)
Data Dictionary -> Technischen Metadaten (Tiefste Stufe)",,,,,,,,
14,Berater,Globale Beratungsfirma,Beratung,"So, we see everything ranging from Excels to Collibra to Ab-Initio to another platform could be Microsoft Perview or anything. (S.5)",Use Case,,,,,,,,,
14,Berater,Globale Beratungsfirma,Beratung,"I have implemented a similar iteration of Collibra at a client for a bank, for a large bank, I would say. And basically, what we did there was, as I said, so they're redeveloping a model. And what they needed to do, they needed to identify what data is required for that model. So, they had a bunch of data requirements. So, they wanted to unify those requirements across the different portfolios that the bank had. Portfolios like they have an agricultural portfolio, they have a private portfolio, private client's portfolio, real estate portfolio. But the underlying data, it is possible to unify across the same, across different portfolios because the definition will more or less be the same in a lot of the cases. So, they not only wanted to identify the requirements, they also wanted to unify. So, we developed an architecture to show how the data flows right from the physical place where it's stored, so like the data warehouse, going from the three layers or the medallion architecture, which is bronze, silver, and gold, where the data is transformed, up to where it's being finalized to be able to deliver to the modeling teams. So, that entire lineage we built out in Collibra using repositories, using different assets like business terms, data attributes, data elements, and assigned ownership to each of those repositories and set up a process, invite that process into business as usual with our colleagues at the bank. And I'm happy to report that even as of a week ago when I checked in with the client, they were still happily using it. (S. 6)",Use Case,Use Case: Data Lineage,,,,,,,,
14,Berater,Globale Beratungsfirma,Beratung,"So keeping that aside for a second, what data catalogs do really well is that they provide you a platform centrally for the entire company to view. So for example, if it's just one Excel on a SharePoint, then yeah, there's access issues, there's auditability issues, anyone can go and change anything there, and then everyone has their own versions of it saved online. But if you have a data catalog centrally stored on a group-wide level for everyone to view, that is a place where you can make agreements and then hold people accountable. So if you set up policies or procedures in a certain way that we have a data catalog, the way we define the data elements in there is that, let's say there's a data definition committee, and we propose definitions to it, it approves, and then there's a governance committee, we propose ownership to it, bring the two people who are involved in deciding that ownership, and decide on a certain ownership. And then after getting approval from all of these committees, then we put information into the data catalog, and so that's your data definition, that's your data ownership, 

and also similarly, your data quality principles that need to be applied under the DQ checks and the thresholds. So you need to have a data catalog in place, you need to have certain standard procedures and committees in place to approve the information being populated in the data catalog. Once you have these two components up and running, then you can say with certainty that, okay, we made agreements with everyone involved, we have stored it in a central location accessible for everyone. So at a later point, if we refer back to it, then we are sure that we made these agreements together. So if something's changing, it's not because of any misunderstandings or any miscommunications, it's because of a change in situation or a change in the mind of a certain person. But certain agreements were made. And that is where they play a really strong role. And I think that to a certain extent, or to a huge extent, tackles DQ issues, ownership issues, definition issues, because if everyone is on the same page about how to define a certain element, then that leads to less incongruity in terms of the usage of that as well. (S.8)",Funktionalität EDC,"Platform für Kollaboration, wobei Regeln, Verantwortungen, Defiitionen festgehalten werden, sodass die Datenqualität verbessert wird",,,,,,,,
15,Data Manager,IT Services,Externe Firma,"They need a common vocabulary where the enterprise data model comes in a picture and you need to have some standard. Otherwise, every system will say, I follow this standard, I follow that standard. Then they are managed by different vendors. (S.8)",Funktionalität EDM,Standardisierung,,,,,,,,
15,Data Manager,IT Services,Externe Firma,"No, my Purview was very, very baby stages. It's still very baby. I would say a lot of companies, it doesn't have lots of nuts and bolts, and it's just a very basic, I would say. We didn't look at it in the Google stack, but Google stack in the data catalog is probably far more mature than Microsoft Office today, even today, right (S.10)",Funktionalität EDC,,,,,,,,,
15,Data Manager,IT Services,Externe Firma,"See, Collibra basically is more of a catalog system. You can define business terms and everything, right? It can support plugging in, like similar to Informatica or any other system, it can support plugging in any of the enterprise data model which you have designed yourself from other systems. They are not modeling tools, right? Erwi is a modeling tool, right? You design the data model into Erwi. Most of the enterprises use Erwi. E-R-W-I, look it up, right? When you want to design a data model. I use another very cheaper version of the tool, it's called enterprise parts. It doesn't cost much. [ERWI] it's a hard tool to use (S.10)",Funktionalität EDC,Business Glossary,,,,,,,,
15,Data Manager,IT Services,Externe Firma,"For example, you design the enterprise data model, then you have something called PolyPro, some other tool, Informatica, whatever you want to use to pull an enterprise catalog together, because it could be self-serve, right? What do you want to do? You want to have basically self-serve. Means that you want to pull the data from all the different systems together, put it in some kind of enterprise data lake, right? And then from there, you basically put it together in the enterprise data catalog. And then you give the business a functionality, because a lot of the catalogs or a kind of model you created yourself (S.13)",Funktionalität EDC,Erstellung eines Enterprise Data Catalogs zur Selbstbedienung und Integration verteilter Datenquellen,,,,,,,,
15,Data Manager,IT Services,Externe Firma,"I often see enterprise data catalog using a system like Collibra or anything is often useful when enterprise is actually, you can consider so many different systems that doesn't speak the same language. Means, it comes from different vendors and everything. You need something to stitch together. (S. 16)",Funktionalität Collibra,,,,,,,,,
16,Data Lead,Private Equity,Externe Firma,"And also maybe it's different for other companies, but for us, a lot of data comes from different actors in the industry and they all have a different format. So it can be a presentation, it can be a PDF, then it's an Excel sheet that they share with us. And then you get all those data on a specific asset manager, let's say, and there is no way to kind of ask, let's say, a chatbot or whatever that could answer you, okay, this is the asset manager, that's where they are located, and this is also what they sent you as a proposal Because all those different informations are stored in different places at the moment or stored in a PowerPoint, but then you also have the problem that in the same slide maybe you have their assets under management, but then you also have competitors' assets under management, so you have to make sure that whenever you extract data, you're not putting one of their competitors to the asset manager that you're looking at and all those problems. And all those things are done manually at the moment and are very time-consuming, but once you have this data architecture in place and you have this data model and it works well and it's clean, and of course it needs someone full-time to kind of manage it and make sure it stays clean, but once you have that, I think what their vision is, like the management board vision, is that it can really, really increase the efficiency first, but also the quality of what you're doing and how extensive the insights you can have on each asset manager as well. (S.8)",Use Case,Zentrale Datenstruktur spart Zeit und Abstimmung,,,,,,,,
16,Data Lead,Private Equity,Externe Firma,"I think slide is the best example for me because it's quite hard to retrieve data from slides unless you go on the PowerPoint, you read it and then you write it down somewhere else. And with all those kind of like AI tools and optical recognition, character recognition and all those different techniques that you can use, I think you can really, really improve the insights you can develop for your investment team or also the knowledge you have about the people you're working with, the different stakeholders and everything. And then I would say you can make way more informed decisions on that. (S.15)",Use Case,Automatisierte Analyse verbessert Entscheidungsqualität,,,,,,,,
4,Senior Partner,Globale Beratungsfirma,Beratung,"[Weg von traditionellen IT-Lösungen, nicht alle bestehenden Daten in neues Tool umschichten, zuerst Fragen, welche Daten sind wichtig] Und eigentlich musst du es andersrum machen. Du musst sagen, pass mal auf, ich habe hier eine bestimmte Anzahl von Problemen, die ich lösen muss. Zum Beispiel jetzt im Mining-Bereich, ich möchte hier meine Predictive Maintenance stark verbessern oder ich möchte so eine Durchlauf-Optimierung machen, um zu sagen, wann ist welcher Truck wo? Wann liefert welche Maschine was? Wo muss irgendein Zug halten? In welcher Zeit und wie kommt das alles zusammen? Das sind so ziemlich interessante, große Probleme. Aber dann würdest du erst mal sagen, wie löse ich das Problem und welche Daten brauche ich dafür? Und jetzt gehst du hin und sagst selektiv, ich baue jetzt ein flexibles Datenmodell, das zukunftsfähig ist und offen ist. Das eben nicht mit irgendeinem System verheiratet ist, wie das früher war. Wo du zum Beispiel alles auf SAP hattest oder auf Oracle. Und du musst sozusagen deine Seele an SAP oder Oracle verkaufen. Sagst du heute, du bildest ein flexibles Datenmodell, das skalierbar ist, sowohl in Bezug auf die Größe als auch auf die Struktur. Das kannst du heute ohne Problem machen. (S.5-6)

Dann sagst du jetzt von diesen 50.000 Sensoren brauche ich jetzt aber nur 500. Dann gehst du hin und sagst, ich fokussiere mich jetzt voll und ganz auf die Integration dieser 500 Data Features, von diesen 500 Sensoren. Baue dir mein Modell ein. Und jetzt hast du dann halt natürlich ein Data Catalog Problem. Weil du willst ja sagen, ich
möchte diese Daten auffindbar machen. Ich möchte diese Daten auch dokumentieren und möchte sie für eine globale Organisation nutzbar machen. Dann hast du wiederum zwei Probleme, die ganz wichtig sind. Das eine ist, wer ist eigentlich der Data Owner? Wer ist eigentlich zuständig für diese Daten? Und das sollte nie IT sein, sondern es sollten immer die Fachleute sein, zum Beispiel die Operators, die sagen, wir sind die Verantwortlichen dafür, dass diese Sensoren sauber sind und dass die Definitionen der Variablen korrekt sind. Und wir machen dann ein Single Source of Truth Prinzip. Das heißt, diese Daten werden nur einmal so in eine Variable verarbeitet und die wird dann im Data Catalog sozusagen als unique abgespeichert. Dann können andere Leute zwar auch Varianten davon kreieren, die müssen aber genau dokumentiert werden. Und das ist heute eher der Fall als früher. Früher war es so, jeder hat sein eigenes Ding gemacht und es ist dann plötzlich ganz viele Versionen desselben Dings mit leicht unterschiedlichen Definitionen.","Use Case
",Use Case: Predictive Maintenance,,,,,,,,
4,Senior Partner,Globale Beratungsfirma,Beratung,"Das hat aber zu massiven Problemen geführt, weil dann geht ein ganzer Report und eine ganze Konsolidierung im Bach runter. Und dann war es bei den Banken immer so, jedes Mal wenn die was an Regulator reporten mussten, zum Beispiel als die UBS mit der Credit Suisse fusioniert hat, da brauchten die halt dann irgendwie 600, 700 Leute, um die ganzen Reports, die alle nicht zusammengepasst haben, selbst innerhalb der UBS oder innerhalb der Credit Suisse, wegen dieser ganzen verschiedenen Regionen, um das alles regulatorfähig zu machen. Das musste alles dann händisch nachgearbeitet werden. Und das ist aber jetzt nur ein Beispiel, das ist bei anderen genauso. Und das vermeidest du mit diesem Single Source of Truth Prinzip. 

Und dafür ist ein Data Catalog sehr wichtig, weil er im Prinzip sagt, hier ist das Offizielle, die offizielle Version und dann kannst du die Governance so gestalten, dass du sagst, entweder darf niemand eine zweite Variante davon schaffen oder jemand darf nur eine private zweite. Variante davon schaffen oder dritte Variante. Oder wenn eine öffentliche Variante geschaffen wird, muss es so klar dokumentiert werden, was ist was. Das ist eine sehr scharfe Anforderung an die Dokumentation, um genau diese Versionsprobleme zu vermeiden, die so unglaublich teuer sind. (S.6-7)",Funktionalität EDC,EDC als zentrale Datenquelle (Single Source of Truth),,,,,,,,
4,Senior Partner,Globale Beratungsfirma,Beratung,"[Berechnung von Kreditkarten Utilization - Marketing vs Risk Dep] So, der Data-Katalog sagt jetzt, pass mal auf, wir haben als Data-Katalog einen Auswuchs von Data Governance. Du sagst, wir haben jetzt bestimmte Regeln, wie Dinge definiert und benutzt werden. Was zum Beispiel wo verwendet werden darf. Und das ist sehr aufwendig. Das heißt, da kommt Compliance mit rein und da kommen Prozesse mit rein. Also zum Beispiel Genehmigungsverfahren, Trails und sowas. Wer was wann wie machen darf. Das Ding wird also plötzlich sehr, sehr, sehr groß. Und der Data-Katalog ist letztendlich das zentrale Element.  (S.7-8)",Use Case,Use Case: Business Rules,,,,,,,,
4,Senior Partner,Globale Beratungsfirma,Beratung,"Wir sagen jetzt nicht, wir machen jetzt eine riesige IT-Implementierung, weil irgendwo ein paar Benefits sind. Im Handel wäre es Pricing, also Preisdifferenzierung. Wenn es um einen ganz wesentlichen Use Case geht, dann Waste-Reduktion, dann hast du auch Assortment, so Assortment-Fälle, wo du sagst, okay, besseres Assortment generiert höhere Umsätze, wenn du die Sachen irgendwie sortierst und aufstellst nebeneinander. Und dann hast du vielleicht noch ein paar andere, aber wenn es keiner von diesen Use Cases, ganz großen Use Cases ist und es gibt andere Gründe, warum das sehr schwer umzusetzen ist, warum auch immer, dann kann es tatsächlich sein, dass du besser damit fährst zu sagen, wir machen das Ganze relativ altmodisch. Wir haben ein gutes POS-System. Das POS-System liefert irgendwelche Reports in mein SAP-System in der Zentrale (S.15)",Use Case,"Bessere Preisdifferenzierung, Waste-Reduction",,,,,,,,
4,Senior Partner,Globale Beratungsfirma,Beratung,"Also man sieht die Zahlen sozusagen zu harmonisieren und ich habe Probleme gehabt. Aber was ich jetzt mache, ich fange jetzt einfach mal an im Data Catalog, ich mache jetzt Dinge so, ich fange an, das alles zu registrieren, wo was ist, das ist so ein Dokumentationstool, ohne jetzt unbedingt meine Systeme alle zu ändern, aber ich fange so langsam mal an, hier und da Sachen zu vereinheitlichen und durch Queries zusammenzufahren, dass ich so, ich baue jetzt mal so ein paar Queries, die aus meinen Crazy Daten diese Konsolidierung automatisieren im Laufe der Zeit. Da habe ich jetzt zwei, drei Developers, die das machen. Aber ob ich das jetzt dieses Jahr oder nächstes Jahr oder in fünf Jahren fertig stelle, ist mir jetzt relativ egal, solange ich das mit 30.000, 40.000 Dollar pro Jahr killen kann, ja. Fange ich damit mal an, weil es No Regret ist. Ich bleibe also immer in dieser grünen Zone, wo es absolut No Regret ist, wo ich gar nicht da rein geraten kann, dass ich jetzt so ein großes, abfäulendes Investment mache, ohne was ich jemals zurück bin. Solche Leute sind auch oft sehr erfolgreich damit, weil die sagen, nach fünf Jahren haben sie dann irgendwie doch ihre gesamte Reporting irgendwie jetzt im Griff, ja. (S.16-17)",Use Case,Implementierung,,,,,,,,
4,Senior Partner,Globale Beratungsfirma,Beratung,"Man kann sich halt vorstellen, dass bessere Daten und bessere Datenqualität zu besseren Entscheidungen führt und auf diesem Pfad bleibt und keine esoterischen Versprechungen macht oder Sachen, die nicht skalierbar sind oder in der Skalierung keinen Wert stiften oder ohne Skalierung keinen Wert stiften, kann man eigentlich kaum falsch liegen. Aber es gibt halt einfach Dinge, die einfach keinen guten Kosten-Nutzen-Verhältnis haben. Wo du wesentlich besser damit dran bist, zwei Leute zu haben, die diese Dinger ständig manuell updaten, als das irgendwie zu automatisieren. (S.23)",Use Case,Bessere Daten führen zu besseren Entscheidungen,,,,,,,,
17,Managing Partner,Globale Beratungsfirma,Beratung,But what catalogues tend to help with is the concept of know your data. So we talk with our clients about know your data. What have you got? And where is it? (S.2),Funktionalität EDC,Besseres Verständnis über Daten,,,,,,,,
17,Managing Partner,Globale Beratungsfirma,Beratung,"[EDC] So what catalogues do a very good job of is, is raising that awareness of know your data, what you've got and where it's stored. Yeah, it allows you to tag information, it allows you to, we often talk about implementing logical domain structures. And that really is just business terms, nouns that describe your data so that you can start to group information together. Again, catalogues can really help to support this concept. So if you take an example of something like, I don't know, a feed that's come out of a risk system, that risk, it might have information about financial products, it might have information about your customers, there might be information about deals and deal sizes, some geographic information about, you know, locations and asset dates. All of that could be stored within a single system and a single feed. But the fact that you know that it's a risk system doesn't give you any insight into all of those things. Yeah, so it doesn't tell you that it's got company financials or geographic or whatever. What catalogues allow you to do is then start to look field by field and classify the contents and information in those fields, so that you start to get a lot more intelligence about the data within the system. (S.2-3)",Funktionalität EDC,"Daten auffinden, taggen, klassifizieren und strukturieren",,,,,,,,
17,Managing Partner,Globale Beratungsfirma,Beratung,"What we'll often see is that if, for example, you've got 17 different fields that hold information related to currencies, those 17 different fields may store a different list of currencies. Yeah, there might be two or three differences. But when you try and pull information together or try and do aggregated reporting, you're going to have a lot of inconsistency because maybe you've got a list of 210 currencies in one system, 215 in a different one, 87 in a different one. So if the data is operating to different standards, you don't necessarily know that. What a catalogue can do is allow you to tag all of those fields as currency fields in the 15 different systems. Then you've got understanding of what you've got and where you've got it. This is all currency data. Now I can start to think about applying consistency and standardisation. So we as an organisation want one list of currencies (S.3)",Funktionalität EDC,Awareness of inconsistencies,,,,,,,,
17,Managing Partner,Globale Beratungsfirma,Beratung,"So if you've got a data analytics system, you can use the catalogue and the concept of owners within the catalogue to actually drive things like who has access to which data in which systems. So catalogues can solve multiple purposes, but we always say that having a standalone catalogue with data in it that only the data office use is a complete waste of time and effort, unless it's embedded and unless you're using the intelligence of that system to drive things like entitlements, the role-based access to systems, so which users can have access to which data in which situations, or things like self-service reporting. (S.4)",Funktionalität EDC,Workflow-Management (Ownership / Zugriffsrechte),,,,,,,,
17,Managing Partner,Globale Beratungsfirma,Beratung,"So if I want to search for data, well I've got this catalogue that tells me that I've got 15 currency fields in 15 systems, okay, I now want to go search for currency data. Suddenly the catalogue can help me to bridge that intelligence gap between the system's view of the fields tagged in different ways, called different things, and the fact that actually these are all currency fields. So we always advocate that the catalogue really should be at the heart of any technology architecture and should be feeding data out into lots of other different tools. (S.4)",Use Case,Use Case: Market Place,,,,,,,,
19,Data Product Owner,Globale Bank,Externe Firma,"In our case, the EDM is actively used by the Data Governance Board, which is composed of both IT and Business representatives. It serves as a central coordination tool to align the strategic data needs of the business with the architectural and technical capabilities of IT.  In this context, the EDM helps: Translate business requirements into data structures. Drive data standardization and harmonization across systems and departments. Define authoritative data sources and resolve data ownership conflicts. Support regulatory compliance, especially in the financial sector where data lineage and traceability are critical  (S.4)",Use Case,Use Case: Central Coordination Tool,,,,,,,,
19,Data Product Owner,Globale Bank,Externe Firma,"According to DAMA, the EDM serves several key purposes: It ensures a shared understanding of data across the enterprise.  It promotes data consistency, both in structure and terminology. It clarifies data ownership and accountability, which are essential elements of data
governance. (S.4)",Funktionalität EDM,"Sicherstellung der Datenkonsistenz, Verbesserung des Verständnisses und Zuteilung der Verantwortlichkeiten",,,,,,,,
19,Data Product Owner,Globale Bank,Externe Firma,"Use Cases of EDM in our organization include: Designing the Enterprise Data Warehouse (EDWH) architecture, ensuring consistency
across ODS, Information, and Analysis layers. Defining key financial and accounting data domains for internal control and external
reporting. Supporting metadata management and integration with Collibra, where high-level
conceptual models are linked to business glossaries and data dictionaries. Acting as a foundation for data quality initiatives, where EDM definitions drive validation rules and anomaly detection mechanisms. Facilitating communication and training, by providing business-friendly representations of how data flows and transforms across the enterprise (S.4-5)",Funktionalität EDM,"Sicherstellung von Datenqualität, Konsistenz und Governance",,,,,,,,
19,Data Product Owner,Globale Bank,Externe Firma,"In summary, EDM is much more than a modeling activity: it is a strategic governance asset that ensures alignment, transparency, and efficiency in how data is used and managed throughout the organization. (S.5)",Funktionalität EDM,"Transparenz, Effizienz, Konsistenz",,,,,,,,
20,CEO,Beratungsfirma,Beratung,"Wir, also APGAR, haben unseren eigenen Data Catalog aufgebaut, wir haben ein vollständiges Datenmodell, wir haben das auf einer Standartenplattform implementiert. Dort ist die Schwierigkeit zum wieder die Daten zu connecten, also das ganze Harvesting zu machen und dann auch die entsprechenden Ressourcen von den Firmen zu bekommen, um so etwas zu machen. (S.3)",Use Case,EDC Herausforderung Implementation,,,,,,,,
20,CEO,Beratungsfirma,Beratung,"Du hast vermutlich x Systeme in deiner Organisation, wo Adressen und Personen pflegen. Vielleicht kann man es über einen Datenkatalog sehen, wo man überall Kunden hat. Man kann dann anschauen, ob es richtig ist, dass man diese Redundanzen hat. Oder gibt es eine Möglichkeit, diese Redundanzen zu eliminieren, damit man nur noch einen Personentopf hat und alles von dort aus kommt (S.6)",Use Case,Datenredundanz erkennen und zentralisieren,,,,,,,,
20,CEO,Beratungsfirma,Beratung,"Da kann einem dann ein Datenkatalog helfen, um herauszufinden, wo man die Daten überall verteilt und was man dazu verwenden kann. Ich denke, das müsste das Thema sein. Wenn du ein Datenprojekt bilden möchtest, für das Reporting, dann ist es sinnvoll, wenn du weisst, von wo die Daten kommen und wie die Daten aufgebaut werden. Oder für das Reporting mit der Data Leakage, wo die Daten herkommen (S.7)",Use Case,Datenherkunft verstehen für gezieltes Reporting,,,,,,,,
20,CEO,Beratungsfirma,Beratung,"[Alternative für Single Source of Truth / EDM /EDC] Stammdatenmanagement. Ich glaube, ich muss das jetzt fast sagen, weil wir das vertreiben. Aber ich bin davon überzeugt, und das ist der CS, ich war dort auch für Stammdatenmanagement verantwortlich. Und ich glaube, je besser deine Stammdaten sind, desto besser sind allgemein deine Daten. Und wenn ich dort immer sage, ist, du deine Daten von Anfang an richtig pflegen, also, du deine Materialien, deine Produkte wirklich von Anfang an richtig einpflegen, dann sind nämlich alle Sachen, die davon abhängig sind, automatisch richtig. Also, und mit System kannst du das sehr gut erreichen. Weil du hast dein Datenmodell und du sagst, wie müssen Daten validiert werden? Also, dass du schon quasi bei der Eingabe der Daten kannst kontrollieren, was reinkommt, respektive kannst verhindern, dass überhaupt Fehler ins System reinkommen. Und dadurch erreichst du automatisch eine höhere Datenqualität. Jetzt kommen natürlich LLMs dazu, da kannst du automatisch Daten extrahieren. Das machen wir auch, du nimmst ein PDF, du kannst automatisch Daten extrahieren, du stehst irgendwo in einen Workflow rein, und da hast du schon mal eine Fehlerquelle eliminiert, wenn wir vom Abschreiben, vom Copy-Paste, hast du schon mal eliminiert. Und ich glaube, dort holst du den meisten Nutzen heraus. Und das hat nichts mit einem Data Catalog zu tun, sondern du musst deine Standarten und Referenzdaten, die musst du im Griff haben, und dann ist die Datenqualität automatisch, alles andere ist gegeben. Das ist, glaube ich, der Punkt. (S.8-9)",Use Case,,,,,,,,,
20,CEO,Beratungsfirma,Beratung,"Genau, wir sind in vielen Projekten, wo du genau dort hin gehst und sagst, wir nehmen die bestehenden ERP-Systeme mit ihren Kundendaten drin, die nehmen wir und konsolidieren sie in einem Standart-Tool. da geht es genau darum, die ERPs zu harmonisieren. Oder dass die Supplier, die Lieferanten, wirklich zusammenkommen, dass sie validiert werden und ein grosser Teil, was wir machen, sind wirklich Workflows, die in diese Tools integriert sind. (S.9)",Funktionalität EDC,,,,,,,,,
21,Senior Datra Product Manger,Agrarindustrie,Externe Firma," Also, das heißt, es gab quasi einzelne Hubs, die bestimmte Datenprodukte betreut haben. Und das ist auch meiner Meinung nach der beste Ansatz, ja, um Daten oder den Wert von Daten in einem Unternehmen wirklich herauszuholen. Ich gebe jetzt mal das konkrete Beispiel für Telemetriedaten (S.3)",Use Case,,,,,,,,,
21,Senior Datra Product Manger,Agrarindustrie,Externe Firma,"Also, wir haben ungefähr 80.000 Maschinen global, die alle 10 Sekunden bis zu 640 Werte liefern. Die Daten haben wir in dem Data Product Management aufbereitet, haben quasi den Kafka Stream dann wirklich in Datenbanken runtergebrochen, sodass sie von verschiedenen Data Scientists oder irgendwelchen anderen Stakeholdern im Konzern verwendet werden konnten. Dafür war es eben auch wichtig, dass wir von unserer Datenbank, wir haben Databricks verwendet, das Lakehouse-Prinzip von ihnen, haben dort dann Informatika angeschlossen.Und da gibt es ein automatisches Screening von Informatika, um dann eben entsprechend die Data Lineage in Informatika zu haben. Also, mit Informatika haben wir einen zentralen Platz, wo wir alle unsere Systeme angefangen haben, fairerweise. Ja, wir sind da noch nicht fertig. Aber das ist die konzeptionelle Idee, dass alle Systeme quasi dort katalogisiert werden",Use Case,Use Case: Maschinendaten,,,,,,,,
21,Senior Datra Product Manger,Agrarindustrie,Externe Firma,"[Databricks] Dafür war es eben auch wichtig, dass wir von unserer Datenbank, wir haben Databricks verwendet, das Lakehouse-Prinzip von ihnen, haben dort dann Informatika angeschlossen. (S.3)",Use Case,,,,,,,,,
21,Senior Datra Product Manger,Agrarindustrie,Externe Firma,"[Informatika] Und da gibt es ein automatisches Screening von Informatika, um dann eben entsprechend die Data Lineage in Informatika zu haben. Also, mit Informatika haben wir einen zentralen Platz, wo wir alle unsere Systeme angefangen haben, fairerweise.  (S.3)",Use Case,Use Case: Data Lineage,,,,,,,,
21,Senior Datra Product Manger,Agrarindustrie,Externe Firma," Aber das ist die konzeptionelle Idee, dass alle Systeme quasi dort katalogisiert werden. Weil das ist auch ein automatisierter Prozess und dass wir darauf dann quasi Data Governance aufsetzen. Und da haben wir auch ein ganzes Team Data Governance, die dann eben mit den entsprechenden Verantwortlichen aus dem Business hier an der Qualität der Datenfelder arbeiten, dass sie dort KPIs entwickeln mit den einzelnen Datenproduktbereichen, so wie bei mir beispielsweise mit Produktdaten oder dann Telemetriedaten oder jetzt, meine Notwendigkeit sind jetzt auch Kundendaten, dass wir hier quasi an KPIs arbeiten, um dann die Datenqualität auch zu verbessern. (S. 3)",Funktionalität EDC,,,,,,,,,
21,Senior Datra Product Manger,Agrarindustrie,Externe Firma,"Bei jedem Projekt, dass ich jetzt, also ich arbeite auch viel an der Standardisierung von Daten global. Zum Beispiel, dass wir mal eine globale Produkthierarchie haben, weil wir haben ungefähr sieben unterschiedliche ERP-Systeme und haben ungefähr 24 unterschiedliche konsumierende IT-Systeme, z.B. CRM-Systeme oder whatever. Das heißt, wir haben eine sehr große Komplexität und wir müssen da sehr stark an Standards arbeiten (S.3) 
Das ist das, was ich auch sehr viel mache, weil das Fehlen von Standards hat zu wirklich, sage ich mal, Komplexitäten geführt, die fast nicht mehr händelbar waren.",Funktionalität EDC,"Standardisierung
Reduktion Komplexität",,,,,,,,
21,Senior Datra Product Manger,Agrarindustrie,Externe Firma,"[EDC]  Ich glaube vor allem auch Transparenz und Knowledge-Entwicklung. Ich glaube, das ist für uns ein ganz großes Thema. Also, vor allem beziehe ich mich jetzt mal auf die Telemetriedaten. Also, wir haben es halt wirklich in dem Bereich geschafft, innerhalb von einem Jahr 35 User auf diese Daten on zu boarden, die eigentlich diese Daten brauchen, aber immer berührungslos. (S.4)

Ich glaube vor allem auch Transparenz und Knowledge-Entwicklung. Ich glaube, das ist für uns ein ganz großes Thema. Also, vor allem beziehe ich mich jetzt mal auf dieTelemetriedaten.Das ist ja doch sehr komplex. Ja, und sage ich mal, ein typischer Landtechnik-Ingenieur ist jetzt nicht so familiär mit Telemetriedaten und was man damit alles machen kann. Also, wir haben es halt wirklich in dem Bereich geschafft, innerhalb von einem Jahr 35 User auf diese Daten on zu boarden, die eigentlich diese Daten brauchen, aber immer berührungslos. Die wussten nicht, wohin sie gehen können. Sie wussten nicht, was wir da für Daten haben. Sie haben sich immer nur beschwert, dass, ja, man macht nichts mit den Daten. Und da hilft meiner Meinung nach, also wir haben dann im Grunde so eine Journey aufgebaut, gesagt, okay, im ersten Schritt sollen sich die Leute halt bei einem zentralen Punkt melden, dass sie Interesse haben, mit unseren Daten zu arbeiten. Dann haben wir wirklich gesagt, okay, im ersten Schritt kriegt ihr immer Zugang zur Informatika, könnt euch da den Katalog mal anschauen. Das war auch alles, also alle 640 Werte waren dort beschrieben.",Funktionalität EDC,,,,,,,,,
21,Senior Datra Product Manger,Agrarindustrie,Externe Firma,"Databricks ist bei euch eher so die Datenbank und dannInformatica ist das Cataloging-Tool? 
Databricks ist Analytics-Plattform und quasi Warehouse-Solution für Telemetrie. Das unterscheidet sich aber pro Datenbereich. Also wir haben da Unterschieden zwischen Telemetrie, Kundendaten, Dealerdaten, Supplierdaten, Finance-Daten. (S.5)",Use Case,,,,,,,,,
22,Chief Data Officer,Bank,Externe Firma,"[EDC] We have our data catalog, but we have our data catalog in detail only for critical data. The critical data for us is the data that can cause you pain if they are wrong, if they are not available, if the confidentiality of those data are compromised. And the huge work of documenting data, the work of documenting data is massive (S.3)

We have three dimensions of criticality. We have the availability. So we have on our catalog all the information that can cause a serious issue to the bank if they are not available. Because they are mainly in a critical process. For example, credit information or payment information, if they are not available, it's a problem. After we have confidentiality dimension, so all the information that are critical in terms of confidentiality. For example, name and surname of the customer. And the information that are critical for integrity purpose. Integrity, we mean the information that if are not correct, can cause real damage for the bank. And on that, we have a data quality control (S.9)",Use Case,,,,,,,,,
22,Chief Data Officer,Bank,Externe Firma,"[EDC] So our data catalog, we have four level data taxonomy. First level is the data domain, information domain. After we have subdomain, after we have data object, and after we have data element. To make you an example, information domain payment, speaking about something that you can understand in the financial services industry. After we can have subdomain outbound payment. Yeah. After data object can be sender information, and after the data element is the IBAN.(S.3)",Funktionalität EDC,,,,,,,,,
22,Chief Data Officer,Bank,Externe Firma,"If you want to connect the offensive part of this, right now in this historical period it's really simple. Because if you have a proper data catalog and you have a semantic layer that is on top of your data catalog, you can put Gen AI in order to read your data easily. (S.4) And this is something where a lot of banks are going. The concept of talk to your data. And this is one of the main use cases, actually, that brings the enterprise to have an enterprise
data model right now.","Use Case
","Use Case: AI 
",,,,,,,,
22,Chief Data Officer,Bank,Externe Firma,"Another stuff that is convenient when you have an enterprise data catalog documented is to have a sort of market data, mainly for reporting purpose and enabling the data mesh. I don't know if you are familiar with the data mesh concept. (S.4)

[Data Mesh] Data mesh is a philosophy because it's an approach, it's not technology. It's a culture-level approach. Data mesh allows you to do self-BI and consume the data as a product. I mean, if you document your data and you have an updated enterprise data catalog, after you can provide this lake of documented data to your business, a business can easily build the report by their own and consume the information. Because otherwise, if the information is not properly documented, you are not able to do reporting. And for this, you centralize maybe the reporting unit. In this model, we have a sort of federation of the operating model. Like this old organization can do reporting in the self-BI mode (S.4)",Use Case,Use Case: Data Mesh,,,,,,,,
22,Chief Data Officer,Bank,Externe Firma,"Yeah, because if you want to build an operating model, our main pain point that we have with our data owner and data steward is, okay, but I want to know what are the perimeter of the information that I own. And I then put several weeks to draw on for the credit purpose to see, okay, the credit amount, the credit limit, et cetera, et cetera. And we carve out the lake of information in the information domain. The people know who are responsible for which data. (S.5)",Use Case,,,,,,,,,
22,Chief Data Officer,Bank,Externe Firma,"[Data Quality & Business Glossary] I think that is the quality of the information because what we are facing now is that not having a proper definition of the information, mainly on the aggregate information or calculated data. You make an example, the paper for the bank is if you are a political exposure person, okay, but you can have different way to calculate it. You know, if you are a member of the PLR or a member of Italian political company, et cetera, et cetera, if you define one rules that define what is that information for you after you don't have quality issue and representing the reality in a different way. (S.5)",Use Case,"Use Case: Business Glossary
Nutzen EDM EDC ",,,,,,,,
22,Chief Data Officer,Bank,Externe Firma,"[Workflow] We are developing a workflow that allows users to request or propose a new business rule. And they insert the definition and the calculation rule. Then the Chief Data Officer can review it and approve with changes if they are needed. And then the data owner of the business rule concept can approve it. And so in this way, we will have a shared definition that all people in the bank can use in one way. (S.6)",Use Case,Use Case: Work Flow,,,,,,,,
22,Chief Data Officer,Bank,Externe Firma,"If you don't have data quality, you cannot do advanced analytics and AI. And what we are doing now is that we are measuring the cost saving across the organization in terms of automatization of reporting process. But we cannot do that part if we don't have a clear understanding and clear data catalog and data model understanding (S. 7)",Use Case,,,,,,,,,
6,Data Manager,Versicherungsfirma,Externe Firma,"[Metamodell - Domainmodell] wir haben uns gerade bei uns in der Signal Iduna darüber unterhalten, wie sieht eigentlich nochmal das Metamodell im Themenfeld Daten aus. Und wir beginnen ganz oben mit einem Domainmodell. Das Domainmodell ist ja hyperabstrakt. Da gibt es nur wenige Domäne innerhalb des Hauses. Also letztendlich sowas wie Vertrag, Person, Schadenleistung, jetzt für die Versicherung wichtig, Marketing, Vertrieb und so weiter. Und dann kannst du halt die Abstraktionsstufen eigentlich beliebig variieren und nach unten gehen. Ich sag mal so, was man sich darunter vorstellen kann, ist halt, wenn zum Beispiel du hast einen Vertrag und darunter hast du dann irgendwie die Subdomäne, zum Beispiel Tarif, dann könntest du dann ein fachliches Datenobjekt darunter nehmen, also dieses typische Business Data Object. (S.4)",Use Case,Use Case: Business Data Object,,,,,,,,
6,Data Manager,Versicherungsfirma,Externe Firma,"[EDM] Also für mich ist es schon eine Art von konzeptuelles Datenmodell, wo ich dann die einzelnen Datenentitäten innerhalb des Hauses mit ihrer Relation in Verbindung bringe. Die große Schwierigkeit des Abstraktionsglobels lassen wir hier erstmal außen vor, aber so vom Grundverständnis. Objekte mit Relation zueinander und Objekte, die natürlich dann halt. bestimmten Qualitätskriterien entsprechen, wo wir dann halt Verantwortlichkeiten haben und vielleicht auch, wo am Ende die Governance und das Data Management aufgehängt ist. (S.5-6)",Implementierungsgrund,,,,,,,,,
6,Data Manager,Versicherungsfirma,Externe Firma,"[EDC] Zum Thema Enterprise Data Catalog habe ich natürlich auch einiges an Erfahrung, weil grundsätzlich wir nutzen Collibra bei uns im Haus. Insofern Enterprise Data Catalog, je nachdem wie man es versteht, kannst du es eng oder breit verstehen. Wenn man es ganz eng versteht, dann ist es eher so, ich katalogisiere meine Daten im Unternehmen und peng, dann ist es vorbei. Und wenn du es breiter fasst, dann ist der Datenkatalog tatsächlich inklusive der Governance Prozesse. (S. 6)",Funktionalität EDC,,,,,,,,,
6,Data Manager,Versicherungsfirma,Externe Firma,"[Collibra] Da haben wir jetzt einen fachlichen Verantwortlichen, der Collibra entsprechend voranbringt. Und jetzt muss man tatsächlich fast nochmal differenzieren, weil Collibra ist ja nicht nur ein Data Catalog. Man subsummiert das ja immer so schnell, das ist unser Katalog bei uns im Unternehmen. Aber Collibra verkauft sich ja selber schon als Data Governance Plattform. Und Data Governance Plattform bedeutet ja, Katalog ist ja erstmal nur, ich katalogisiere meine Daten, damit sie auch erfindbar sind, damit auch vielleicht die Verantwortlichkeiten dranstehen, ansonstiges. Data Governance und Data Management, also jetzt für diese Plattformen, da ist ja noch viel mehr, da ist ja auch noch Quality, da sind Berechtigungsprozesse beziehungsweise Datenfreigabenprozesse, Datenanforderungsprozesse und so weiter (S.6)",Funktionalität Collibra,,,,,,,,,
6,Data Manager,Versicherungsfirma,Externe Firma,"Dann war das so, dass ich gesagt habe, okay, es gibt ja diverse Disziplinen im Data Governance, Data Management Umfeld. Was könnte uns denn helfen? Und dann haben wir gesagt, okay. Häufig ist halt das Thema Stammdaten, also Master Data, die wichtigsten Daten im Unternehmen. relativ schnell für uns entdeckt, das ist wahrscheinlich nicht der Hebel der Signal Iduna, wo wir hier gut vorankommen können (S.9)",Use Case,,,,,,,,,
6,Data Manager,Versicherungsfirma,Externe Firma,"Und das war dann halt letztendlich irgendwann der Punkt, wo wir gesagt haben, okay, wenn wir Master Data machen wollen, dann müssen wir ja im ersten Schritt wissen, welche Daten haben wir denn eigentlich? Und was sind denn eigentlich die wichtigsten Daten? Weil so grob konzeptuell kannst du dir ja schon ganz viele Gedanken machen, aber so wirklich aus den Operations heraus das zu sagen, ist halt superschwierig. Und wir haben halt gesagt, okay, auch das Beispiel Quality, also wie willst du Qualität definieren, wenn du nicht weißt, was die Daten fachlich bedeuten sollen und so weiter (S,9)",Funktionalität EDM und EDC,,,,,,,,,
6,Data Manager,Versicherungsfirma,Externe Firma,"Was wir jetzt gemacht haben, womit wir jetzt begonnen haben im letzten Jahr, so perspektivisch wollen wir in so eine Art von Data Mesh reinlaufen. Und da gibt es halt entsprechend Datenprodukte. Und wir haben halt überlegt, okay, Collibra hat ja auch Marketplace mit Data Products und so weiter integriert. Lass uns das doch mal auf die Signal Iduna anwenden. Klar, man nimmt jetzt nicht eins zu eins das, was Collibra liefert, sondern macht das so, wie man es selber braucht. Aber Collibra ist da flexibel genug sozusagen (S.12)",Use Case,Use Case: Data Mesh,,,,,,,,
6,Data Manager,Versicherungsfirma,Externe Firma,"Dieses Thema Data Product dagegen ist greifbar. Weil du öffnest halt Collibra, den Marketplace, du findest da ein Produkt, welches du kaufen kannst, welches du shoppen kannst. Und wo dann nicht nur jetzt Katalog-like im Sinne von schön dargestellt ist, was da drinsteckt, sondern wo auch die Governance embedded ist sozusagen. Also ein Data Product ist erst ein Data Product, wenn die Governance stimmt. Das ist ja das Geile. Sobald du Qualitätskriterien hinterlegt hast, sobald klar ist, wer dafür verantwortlich ist, sobald die Definitionen der Attribute und der Fachlichkeiten drin ist, sobald SLAs existieren,die dir sagen, was kannst du denn eigentlich erwarten, wenn du dieses Produkt konsumierst. Und vieles mehr. Vieles an Data Governance Themen, die man erst mal so relativ abstrakt findet, die kann man dort in diesem Datenprodukt implementieren.

Nutzen: Wenn irgendjemand im Marketing Datenfreigaben braucht, wenn irgendein Use Case Daten für seine App braucht oder Sonstiges, dass wir hier tatsächlich ein Angebot mit inkludierter Governance anbieten, welches im gesamten Haus sozusagen notwendig ist. Und bei uns ist das erste Datenprodukt eins tatsächlich, das schon etabliert ist, was aber momentan viel mit Wiki und so weiter arbeitet, die eigentlich davon weg wollen, weil das sehr viel manuellen Aufwand bedeutet und wir bieten denen Automatisierung. Das heißt, wir haben ein etabliertes Datenset, welches wir zu einem Datenprodukt weitergebaut haben, welches jetzt exklusiv über die Plattform zur Verfügung steht und bezogen werden kann (S.13)",Use Case,Use Case: Data Marketplace und Data Product,,,,,,,,
8,Experte,SAP,EDM / EDC Anbieter,"Und bei uns kann man dann, also hier haben wir den Überblick, was wir hier alles ermöglichen ist letzten Endes, wir haben für den Konsumenten vom Data-Product die Möglichkeit, eben Datenprodukte zu finden, sich anzuschauen, zu verstehen, auch letzten Endes ein neues Datenprodukt anzufordern.

wir wollen Collibra einsetzen, um Datenprodukte zu verwalten, da war es so, dass uns Collibra selber gesagt hat, wow, wir haben in unserem Katalog selber noch gar keinen Asset-Typ, also dort wird es immer noch Asset-Typen klassifiziert für Datenprodukte. Wir haben gar nicht so ein Standardobjekt, aber unser Tool ist so flexibel, ihr könnt das machen. Und sie haben uns auch gesagt, dass von 100 Kunden zu dem Zeitpunkt damals ungefähr 10 Prozent wirklich einen Datenprodukt-Ansatz fahren wollten. Und Ende letzten Jahres waren es aber schon 30 Prozent.",Use Case,Use Case: Data Product Cataloge (Datenprodukt Ansatz) ,,,,,,,,
8,Experte,SAP,EDM / EDC Anbieter,"Das heißt also, man kann vom Katalog raus dann letzten Endes das Datenprodukt shoppen. Also was man da shoppt, ist ein Element des Datenproduktes. Es ist immer ein Output-Port. Also das heißt, das kann der Zugriff auf Daten sein via API, der ein Output-Port-Typ. Oder das kann einfach ein View sein in Datasphere, wo wir dann letzten Endes den Zugriff auf die Daten ermöglichen. Das wäre also so ein Datasphere-View-Sharing. Also es gibt verschiedene Use-Cases, wie man dann letzten Endes den Output eines Datenprodukts halt shoppen kann.

 Systeme, Daten oder eben jetzt hier auch Analytics ist, wird eingeordnet in Domänen, wie die SAP aufgestellt ist. Also es gibt bei uns natürlich Sales, Marketing und so weiter und so fort. Und dann kann man sich letzten Endes das hier so anschauen, was es alles gibt. Im Moment sind es schon 381. Wir werden aber irgendwann bestimmt eher in Richtung 2000 oder noch mehr kommen. Und wenn ich jetzt mal hier zum Beispiel allein für die Stammdaten gucke, also wenn jetzt jemand
sagt, ich brauche Referenzdaten, wie so ein Industry Code oder Country Code und so weiter, dann kann ich das hier nicht nur anschauen, sondern ich kann es shoppen und in den Spacereinlegen und dann sicherstellen, dass das, was ich modelliere, exakt die Zuordnung der Country Codes hat, so wie die SAP das haben will. Wenn ich jetzt zum Beispiel auf den Account Master Data gehe, das wären jetzt unsere Kundendaten. Also wir sind dann hier beschrieben, der Zweck. Man sieht dann auch, was für ein Typ das ist. Das kommt also direkt aus dem Quellsystem. Man sieht die Flags, was alles approved ist. Man sieht, welches Team dahinter steckt. Man kann sich in den Responsibilities dann auch angucken, wer sind die Domain Owner, die Product Owner, die Engineers. Also wenn man dazu letzten Endes Fragen hat. Workers, Counselors, Businesses sind da alles drin. Das heißt also, was da ist, kann man benutzen. Und was man jetzt wirklich verwenden kann, sind diese Output Ports. Das heißt, wir haben hier einmal die Stammdaten via API oder via Spacesharing. Da ist so ein Shopping-Icon. Das kann ich jetzt auswählen, in meinen Basket packen, Checkout. Dann bekomme ich auf der Modellierungsumgebung meinen eigenen Space mit genau eben diesem Datenset drin. Und
dann kann ich mir noch andere dazu shoppen. Und dann kann ich meine eigenen Daten mit reinbringen. Was eigenes machen. Und dann bin ich auf der Provider Journey und kann mein eigenes Datenprodukt hier wieder listen.",Use Case,Use Case: Shop-to-Provision,,,,,,,,
8,Experte,SAP,EDM / EDC Anbieter,"Und der letzte Teil wäre dann halt, dass wir halt auch einpaar Qualitätsmetriken an das Datenprodukt dranhängen, damit man auch versteht, was man
da so shoppt. Der zweite Teil ist dann mehr aus der Sicht eines Data-Product-Owners oder auch des Engineers, also der das Datenprodukt letzten Endes baut.",Use Case,Use Case: Qualitätsmetriken ans Datenprodukt hängen ,,,,,,,,
8,Experte,SAP,EDM / EDC Anbieter,"Der zweite Teil ist dann mehr aus der Sicht eines Data-Product-Owners oder auch des Engineers, also der das Datenprodukt letzten Endes baut. Und dort sind dann alle Capabilities, die man halt braucht, um so einen Lifecycle vom initialen Anlegen eines Datenprodukts bis dann vielleicht auch wieder zum Retire-Step. Ganze Governance, wie man da drum herum braucht, aber auch die Insights. Also wer verwendet mein Datenprodukt für was? Also das wäre die Lineage. Und auch, wie kann ich das weiter optimieren? Und wie kann ich den Konsumenten zeigen, was meine weitere Roadmap-Planung ist? Also vielleicht füge ich noch einen anderen Output-Port-Typ hinzu. Und der letzte Teil von unserem Produkt ist letzten Endes wirklich die Governance, die wir in meinem Team letzten Endes dann auch ausüben müssen. Das heißt, wir definieren die Rollen, die Verantwortlichkeiten. Wir machen auch den Sharepoint für das Enablement. Wir machen das ganze Data Literacy-Thema und machen auch die Integration in andere Kataloge. Aber das ist vielleicht nur mal so als grober Überblick (S.3)",Use Case,Use Case: Lineage Nachverfolgbarkeit,,,,,,,,
8,Experte,SAP,EDM / EDC Anbieter,"Früher war Analytics bei SAP dezentral in Silos organisiert (z. B. Sales, Marketing, HR), was schnelle und fachnahe Analysen ermöglichte. Der Nachteil war jedoch eine unübersichtliche Tool-Landschaft und fehlende Entwicklungsmöglichkeiten für Mitarbeitende. Daher wurde die Analytics-Funktion zentralisiert, was allerdings die Nähe zum Fachbereich reduzierte. Um dies auszugleichen, werden nun Self-Service-Funktionen und standardisierte Datenprodukte im semantischen Layer geschaffen. So können Business-Nutzer auf vorhandene Datenpakete zugreifen und Use-Cases schneller umsetzen, ohne alles neu entwickeln zu müssen. (S.4)",Use Case,,,,,,,,,
8,Experte,SAP,EDM / EDC Anbieter,"Im neuen Ansatz können Nutzer im „Data-Field“ selbstständig auf vorhandene Datenpakete zugreifen, sie mit eigenen Daten kombinieren, modellieren und publizieren. Andere können darauf aufbauen – das steigert Effizienz, beschleunigt Entscheidungen („Insight to Action“) und erhöht die Transparenz darüber, welche Daten vorhanden sind. Durch einheitliche Standards und Prozesse entsteht zudem eine bessere Datenherkunft (Lineage), was die Nachvollziehbarkeit verbessert. Man unterscheidet zwischen primären Datenprodukten (z.B. aus Stammdaten direkt aus Quellsystemen) und abgeleiteten Datenprodukten, die auf bestehenden Daten aufbauen (z.B. in Apps). Die Nutzung gemeinsamer Stammdaten erhöht die Qualität und Konsistenz. Aus Sicht der Datenqualität ist dies ein großer Vorteil – besonders im Zusammenhang mit KI, wo saubere Daten entscheidend sind. (S.4-5)",Funktionalität EDC,,,,,,,,,
8,Experte,SAP,EDM / EDC Anbieter,"Und andere, wie eine Porsche, die haben dann auch wegen den Personal Identifiable Data und GDPR, wegen diesen Marketing-Use-Cases, dann angefangen, das zu
machen.",Use Case,Use Case: Personal Identifiable Data (Marketing) ,,,,,,,,
8,Experte,SAP,EDM / EDC Anbieter,"Sustainability ist auch ein super Use Case, weil für Sustainability brauchst du Daten aus der ganzen Firma. Bei uns war es zum Beispiel so, dass man gesagt hat, okay, wenn ein SAP-Kunde jetzt Cloud-Software einsetzt, dann hat er irgendwann auch das Recht zu verstehen, was der Carbon Footprint ist. Und wie kommen wir jetzt überhaupt da dran? Und dann haben wir festgestellt, dass die Mitarbeiter in Cloud Operations, also man deckt dann zum Teil auch viel Schatten-IT auf, dass die tatsächlich Logiken entwickelt haben, um den Stromverbrauch unserer Server umzulegen auf eine einzelne Instanz von Kunden und das also zuordnen können mit ihrer Logik. Und das heißt, die machen jetzt ein Datenprodukt, wo man einfach nur sieht, Kunde, Stromverbrauch, man sieht es dann pro Tag und auch sie abverteilt. Und wenn jetzt jemand für Sustainability zuständig ist, dann will er sich das natürlich schotten und verbinden mit anderen Sustainability-Metrics, die er braucht.",Use Case,Use Case: Sustainability,,,,,,,,
8,Experte,SAP,EDM / EDC Anbieter,"[Initiative Katalog zählt da darauf ab, zu zeigen, was es gibt und auch dann die Nutzung der Daten auch enorm zu erhöhen. Aber ich glaube, was der Katalog an sich im ersten Schritt erreicht, ist einfach, was gibt es überhaupt alles. Und wenn man dann auch noch, was ja auch nicht jeder macht, dann aber einen Datenproduktansatz fährt, dann packt man eben die Governance, die man braucht, rund um diese Daten drum herum und ermöglicht dadurch einfach eine viel größere Gruppe innerhalb der Firma den Zugriff auf die Daten. Was dann letzten Endes dazu führen sollte, dass einfach das Analytics-Reporting oder auch das Decision-Making viel besser wird (S.7)",Use Case,,,,,,,,,
24,Head of Data EMEA,Globale Bank,Externe Firma,"Data gathering and data presentation represents a significant chunk of the time. So by facilitating the data access, you are saving yourself time as a data analyst or a data person, and you are saving them time. (S.5)",Use Case,,,,,,,,,
5,Data & AI Experte,Beratungsfirma,Beratung,"[Alation] Wir haben uns dann aber für Alation entschieden. Wir waren für Alation der dritte Kunde in Europa und haben sozusagen dann, das war Mitte 2018, auf dem Cloud basierten Amazon Data Lake, Alation als Data Catalog mit draufgesetzt. (S.2)

[UseCase Alation] Alation zu der Zeit sehr stark auf dieses, die haben so einen SQL Feature innen drin, mit dem man sozusagen SQL Queries in Alation schreiben kann, gegen verschiedene Backends connecten kann. Und wir das sozusagen unseren Analysten verkauft haben, hey, das ist unser eigenes SQL Interface, mit dem ihr jetzt, egal ob Data Warehouse oder Postgres oder Impala, was ist die SQL Query schreiben könnt. Über diese Schiene haben wir es eingeführt (S.2)",Use Case,"Use Case: SQL Query
Alternative Tools",,,,,,,,
5,Data & AI Experte,Beratungsfirma,Beratung,[Alation] Das Cloud hat dann den GDPR Vorfall gehabt. Es gibt so einen Pressebericht dazu. Wir konnten gewisse Daten nicht löschen (S.3),Implementierungsgrund,,,,,,,,,
5,Data & AI Experte,Beratungsfirma,Beratung,"[EDC]... Und in dem Zuge haben wir dann relativ Druck gehabt, zu verstehen, in welchen Systemen welche Daten sind. Und da hat uns der Data Catalog in dem Moment wieder sehr geholfen. den Data Catalog wirklich mit der ganzen Firma auszurollen, mit allen Datenquellen zu connecten, um dann zu wissen, was drin ist. (S.3)",Use Case,,,,,,,,,
5,Data & AI Experte,Beratungsfirma,Beratung,"[Ikea & Novartis Anektdote] Ich habe für Shell, für Novartis und Ikea Beratung gemacht. In diesen Firmen sind riesengroße multinationale Firmen, die operieren ihre Standorte sehr getrennt voneinander, haben in jedem Standort ein eigenes SAP-System. Da war auch immer das Thema, wie bringen wir die Daten zusammen. Man wollte eigentlich nie ein zentrales Team hinsetzen, weil man immer gesagt hat, das ist das Bottleneck. Aber du brauchst erst mal ein zentrales Team, was gewisse Standards aufsetzt. Und dann muss die Motivation wieder über den Business Case gehen (S.12)",Implementierungsgrund,,,,,,,,,
5,Data & AI Experte,Beratungsfirma,Beratung,"[AI mit EDC/EDM] Aber um wieder auf Data-Catalog, Data-Modelle zu kommen, das ist auch eine große Chance, weil die AI kann sehr vieles, je mehr sie weiß, automatisch befüllen, dokumentieren, beschreiben. Wenn ich zum Beispiel schaue, ich habe das letzte Mal 2020 wirklich in Action bei Scout24 gesehen, wenn du mal 100.000 SQL Queries über Alation gemacht hast, hat Alation ein unglaubliches Wissen, wie das Business-Modell funktioniert, weil ja jeder SQL-Query-Business-Model drinsteckt. Und dann konnte 2020 schon ohne LLMs Alation extrem gut dir sagen, wie deine SQL-Query die nächsten Dinge beschreiben wird, wohl aussehen wird. Und wenn ich mir noch denke, wo man das LLM auch noch mit reinkommt, wenn ich so Sachen wie Co-Piloter und so anschaue, ist das ja dann nochmal ein ganz anderes Lab. Und das bringt für mich ein Riesenpotenzial, dass ich dadurch sehr viele Themen viel einfacher lösen lasse. (S.15)","Use Case
","Use Case: AI 
",,,,,,,,
7,Data Architect,Versicherungsfirma,Externe Firma,"[EDM] So it represents basically all of the data assets of the organization, how they are placed in the organization, which also goes very closely linked with the data architecture as well. It's one of the founding pillars of the data architecture. Where are your assets located physically? How they are modeled? How they are standardized across the organization? What is the relationship between them? What is the data landscape? So all of that is generally addressed through the data models and the data model is the backbone of the data management. So your data management platforms are successful if you have a proper data models in place. And one of the goal always when I create or when I implement data models is the data verification. So the fair standards or fair principles of the data that data is findable, data is accessible, data is interoperable and data is reusable. So creating the reusable data assets is one of the purpose of the data model as well. (S.3-4)",Funktionalität EDM,,,,,,,,,
7,Data Architect,Versicherungsfirma,Externe Firma,"[EDM - Harmonisierung] So harmonizing all of these data points to the common data model so that it represents the business language of, let's say, my organization. So when I talk about, let's say, a financial instrument, what it means for the Bloomberg data, what it means for the MSCI data, what it means when it comes to different asset class such as mortgages or loans or real estate. So it's the same terminology, but has a little bit of different meaning when it comes to the data universe behind. So harmonizing all of that, which is also one of the use case for master data management. So that is addressed through the data model. 

Nutzen: And the common understanding or creating this common data model is the goal behind this activity, that financial instrument is uniquely identified and uniquely understood by each and every one in the organization.And the business partner also handles the securities and also consumes the securities. So these are different relationships between the business partner and instrument. So those are also reflected in the data model.(S.4)",Funktionalität EDM,,,,,,,,,
7,Data Architect,Versicherungsfirma,Externe Firma,"[Aufbau EDM] So in the data model itself, we have three layers. Perhaps you are aware of the conceptual or sometimes even it starts with the context. So the conceptual, logical and physical. Physical can be different for one logical model. It can represent many physical interpretation, but the logical and the concept represents one thing unified across the organization. So that's the data model.",Funktionalität EDM,,,,,,,,,
7,Data Architect,Versicherungsfirma,Externe Firma,"[EDC] And then when it comes to data catalog, one of the goal is also to make our business users data literate, meaning the data literacy in the organization. So they are aware and they know how to access or whom to contact when it comes to a certain data point. So what data points are available in my organization? So the data owner, the data stewards, all of that is represented in the data catalog. And there are many ways how to implement data catalog and various tools in the market to implement the data catalog. But one of the primary focus of data catalog is also to enable data governance and data literacy in the organization (S. 5)",Funktionalität EDC,,,,,,,,,
7,Data Architect,Versicherungsfirma,Externe Firma,"[EDC & EDM] So again, coming back to the FAIR principles, so you make your data sets findable and accessible and interoperable in the organization and reusable. So these are the common principles that are addressed by the enterprise data model and the enterprise data catalog. (S.5)",Funktionalität EDM und EDC,,,,,,,,,
7,Data Architect,Versicherungsfirma,Externe Firma,"[Collibra EDC] so we have a Collibra for the enterprise data catalog and all of our data assets, inventories are available in the Collibra and through marketplace. So it's like a checkout process, like a cart, like a shopping cart. You go to the marketplace, you find I'm interested in the prices data I want to check out. Then you select that product, then you check out and then the request is sent to the data owner with the proper justification behind. And then you are also made aware of the cost that will incurred and then you take a decision whether you want to check out and then the roles are assigned to you to access that data and then you will be provided with a platform link how to consume that data. So that's generally what is covered in our Collibra data catalog (S.5)",Use Case,Use Case: Data Marketplace,,,,,,,,
7,Data Architect,Versicherungsfirma,Externe Firma,[Erwin EDM]  And for the data model also we have a tool which is like Erwin. I'm not sure if you know it's a data modeling tool. So it connects to different applications that we have. It connects to SAP ERP applications. It connects to Azure Databricks. So these are main two technology stacks in the organization at the moment and Erwin connects to both of them for the physical implementation of the data model. And all of our data assets are available in the cloud platform. So Erwin is also a cloud-based tool where everyone from the organization can look at the data model that we have built and they can really see I'm interested in this table or I want to know more about this data domain or this data product which they see in the data catalog and they both are interconnected (S.5-6),Funktionalität EDM,Alternative Tools: EDM Cloud based Tool Erwin ,,,,,,,,
7,Data Architect,Versicherungsfirma,Externe Firma,[EDM & EDC] So enterprise data model is available in the enterprise data catalog as well as one of the assets and then they can see there how the data assets are linked with each other. (S.6),Funktionalität EDM und EDC,,,,,,,,,
7,Data Architect,Versicherungsfirma,Externe Firma,"[EDM & EDC] whenever there is a change in the system or whenever there is a new requirement or change in the requirement, I use it for the impact assessment as well. I know which data products will be impacted, what is the impact, where I need to address, what will be the overall efforts based on certain parameters that we have defined. So other than just making the business aware of the available data assets, it's also used by the leadership team to drive day-to-day activities as well. What are the impacted areas or the impacted systems that you need to consider? The regression testing, the quality assurance of the data, the interoperability of the data (S.6)",Use Case,Use Case: Impact Analysis ,,,,,,,,
7,Data Architect,Versicherungsfirma,Externe Firma,[Besserer Überblick] So every system was requesting the same data points over and over again. So when we realized that it's the same data point that can be requested only one. (S.7),Use Case,,,,,,,,,
7,Data Architect,Versicherungsfirma,Externe Firma,"[Kostenmanagement] So that was also eliminated, because when we realized how the data model is structured, and when we looked at how we are sending the request out of this master data management system, we found out that gap and we had to change our implementation strategy. So that is also something which helped us to understand why our costs are going up. And you can optimize it. (S.8)",Use Case,,,,,,,,,
7,Data Architect,Versicherungsfirma,Externe Firma,"[Data Lineage - EDC]  You can see where the data is going. Because when we work with the third party market data suppliers, they have very strict requirements on how to consume their data products. So for example, if I'm getting data from Swiss National Bank, they say that it is only accessible only in the Switzerland market unit or only in the Switzerland. So I cannot use that data point in Germany, for example (S.8)",Use Case,Use Case: Lineage Nachverfolgbarkeit,,,,,,,,
7,Data Architect,Versicherungsfirma,Externe Firma," Whatever sale you have at retail level, so at postcode level, is only accessible only in Switzerland. But when a user from Germany tries to see that information, their data license restriction says that the postcode level information is not accessible outside of Switzerland (S. 9)",Use Case,Use Case: Geofencing,,,,,,,,
7,Data Architect,Versicherungsfirma,Externe Firma,"[EDC] I believe such restrictions are there in every country. And Data Catalog is again a place where you know how the data is being transformed, from what granularity to which KPIs and which metrics it is flowing, where those are displayed and who can access. (S.9)",Funktionalität EDC,,,,,,,,,
7,Data Architect,Versicherungsfirma,Externe Firma,[AI Possibility] One aspect which you can consider there is or which I consider is that if you want your organization to be a data driven and nowadays AI driven decision making organization it is not possible without enterprise data model or enterprise data catalog (S.12),Use Case,"Use Case: AI 
",,,,,,,,
7,Data Architect,Versicherungsfirma,Externe Firma,"[MDM] So MDM will provide you a methodology to master your data but if you are not feeding all of the data sources to your MDM, the output of that MDM will never be complete. If you have 10 data sources that you want to master but if you know if you don't know what those 10 data sources which is typically you will find out in the data catalog you will never know how many input should be given to your MDM system. MDM is just like an engine which will produce something based on what is fielded to it and it will give you the standard output for all that input data but if you are missing on the input side itself which is a gap which MDM cannot close by itself. It's garbage in garbage out generally. If you don't know what you want to master or how many sources you want to master MDM cannot do that for you. (S.13)",Use Case,"Alternatives Vorgehen, um Datenqualität zu verbessern (MDM), nicht möglich ",,,,,,,,
7,Data Architect,Versicherungsfirma,Externe Firma,"[EDM & EDC] Yes, so EDM and EDC are I would say typically nothing to do with the master data management because master data management systems will only provide you golden copies of the data but how do you want to model that information is addressed through your data model. So you can get the golden copy of the data it's really like a gold nuggets that you found in the land but you don't know what you want to do you don't know how to model it then you don't know how to use those gold nuggets. If you want to make a jewelry out of it you need to have a proper process behind a proper data model behind which part goes where which data goes where how to connect different master data systems together that is addressed through the enterprise data model where you model your data assets from the organization perspective. So master data management is one piece of the entire puzzle I would say. yeah. And enterprise data model not just work with the master data management but one of the input to the enterprise data model is master data management. Then there are reference data there is a transactional data that you need to bridge with the master data. Otherwise your master data is just sitting in the organization doing nothing. So that relationship and data harmonization standardization is addressed through data model yeah and the data catalog is for the end user consumption perspective and for the reusability that you do not create the same golden copies again and again. Once it's established all systems should use that golden copy of the data which is possible through data catalog if it is listed or registered in the data catalog. Then all other teams can also start using it. Yeah, so I would I consider those as two separate buckets. (S.14)",Use Cases,"Alternatives Vorgehen, um Datenqualität zu verbessern (Stammdatenmanagement), nicht möglich",,,,,,,,
26,Data Executive,Finanzdienstleistungen,Externe Firma,"[Metadata 360] So at a high level, the key thing I drive is trying to actually bring together the technical business governance metadata of our assets onto one platform to provide a 360 degrees, like I call it metadata 360, because all the three are important to really leverage data as an asset. So hopefully that gives kind of a high level. (S.2)
So the technical metadata is what usually most of the different data catalogs have. So webring that, and that is automated. But the hard part is enriching the technical metadata or your schemas to be more clear what it means. Schemas need to enrich with business metadata and governance metadata. And that
information is scattered all over the place. It can be in some spreadsheets. It can be in some document. It can be an email in somebody's head or things like that. So trying to curate and bring it into Collibra and map it to your technical metadata, then you
get a complete 360-degree view of metadata for a data asset
..we're trying to ingest the metadata from those platforms into Collibra. So again, it's like various tech stacks. So though mostly we are on GCP, which is
a Google Cloud, we still have a few other flavors of tech stack like BigQuery, Bigtable, Firestore, and sometimes it may not even be on GCP...
each of these platforms across the globe have their own data catalog. So the intention is not to really replace those catalogs because from an operational point of view, those catalogs are needed and you can think of it like a lockdown catalog where nobody other than the automated process has access to the catalog....
What we do is we try to integrate with this catalog and bring it into Collibra.
And again, keep in mind what we have is kind of a real-time integration process. Once we integrate it, then after that, it's completely automated.

So the technical metadata is what usually most of the different data catalogs have. So we bring that, and that is automated. But the hard part is enriching the technical metadata or your schemas to be more clear what it means. Schemas need to enrich with business metadata and governance metadata. And that
information is scattered all over the place. It can be in some spreadsheets. It can be in some document. It can be an email in somebody's head or things like that. So trying to curate and bring it into Collibra and map it to your technical metadata, then you get a complete 360-degree view of metadata for a data asset. So that is what takes time. Bringing the technical metadata can be straightforward, but then somebody has to go and enrich it. And there's no easy way to do it.
So kind of at a high level, that is what, and that's why we call it Enterprise Data Catalog, because EDC is not localized to a platform or a region. It has to be, if you're a global company, there should be one. So all your employees across the globe should just go to one platform and see that.
It's kind of a catalog of catalogs. ",Use Case,Use Case: Meta Data 360 (Catalog of Catalogs) ,,,,,,,,
26,Data Executive,Finanzdienstleistungen,Externe Firma,"[Vorgehen Best Practice?] So ideally, between 20 to 30% of your data should be what is the CDE or the critical data element. So what you do is as you're building your metadata dictionary and data catalog, you try to start flagging the data that is important that you have to govern and manage responsibly. In short, that means you have to invest time and money and people on that. So once you identify that, then you start looking at, OK, now let me make sure that that much data is clean, it's accurate, all the data quality things of timeliness, relevance, consistency. You can start enforcing that because that is ultimately that will help you then use the data. So key thing is that (S.5-6)",Use Case,Use Case: Einteilung Data in Critical Data  ,,,,,,,,
26,Data Executive,Finanzdienstleistungen,Externe Firma,"[Impact on Analysis - Verknüpft mit Lineage]  This applies to any industry, any organization that treats data as an asset. So use case number one, I call it actually impact analysis. So what that means is, like, for example, if you're getting data from an outside supplier, a data provider from data marketplace, and most of the time it is a subscription-based service because I may have your data up till now, but every month you are creating new digital footprint. (S.6)",Use Case,Use Case: Data Analytics ,,,,,,,,
26,Data Executive,Finanzdienstleistungen,Externe Firma,"[Lineage] So using Collibra, you can see, like, if I stop getting this field and you trace the lineage from your ETL pipeline all the way to the product and services, you know which of your customers are going to get impacted, right? And it's important because you don't want to be reactive there because when it happens, it's going to stop coming and then your customers are going to look at their insight, at their models and agents, and they will say, what's going on? (S.6)",Use Case,Use Case: Lineage Nachverfolgbarkeit,,,,,,,,
26,Data Executive,Finanzdienstleistungen,Externe Firma,"[Audit] If you have a data problem, it's not the end of the world. But if in your manufacturing pipeline, the batch job that actually makes the shoes, something is wrong. And now the shoe is all being manufactured without a sole. That's a big problem. So same thing for companies that generate data products. If there is any data issue, if the customer comes back and says, what's going on? Like, why is this giving me wrong insight? You should have the ability to trace back and see what's going on. And that is called auditability. (S. 7)",Funktionalität EDC,Auditability,,,,,,,,
26,Data Executive,Finanzdienstleistungen,Externe Firma,"[Ideation] And again, when you say ideation, what do you mean? You're building a data product. So you're not building a car, you're not building a plane, you're not building sports goods, or you're not building anything. All you're building is data. The raw material for data product is data. But if you don't know what raw materials you have, how are you going to ideate? So very first thing is, as you're ideating, you need to know exactly what do I have. So when you go into Collibra, you should have a data catalog that tells you these are the assets. (S.7)",Funktionalität EDC,Auffindbarkeit,,,,,,,,
26,Data Executive,Finanzdienstleistungen,Externe Firma,"[Geofencing and Ideation]  So in Europe, they say you cannot move your consumer data outside of the European Union. So it is within the geographical boundary of European Union, so that is called geofencing. We are trying to build an AML or a fraud product that needs to identify people across continents. They will not have access to the live data but they will have access to the metadata and they can see. Of course, they will still have to go through the process of requesting access to the live data once they build the use case. But it makes their job very easy and the process fast when they know exactly what is available and what they can do with it when they go to the legal compliance and privacy team. They can go with all the supporting documents and say, I need access to this data and this is what are the restrictions and this is my use case. So with actually Collibra, they can do that because the metadata across the globe, across all platforms is available in one place. (S.9)",Use Case,Use Case: Geofencing,,,,,,,,
9,Chief Data Officer,Wirtschaftsprüfung,Beratung,"[EDM] die Business Seite ist natürlich daran interessiert, das zu haben, um eben eine einheitliche Architektur zu haben, ich möchte nicht 50 verschiedene Software Tools haben, die alle eine komplett andere Architektur haben, weil das bedeutet ja auch, ich habe null Skaleneffekte, wenn es ums Teaming geht, also ich habe ja ein Interesse daran, dass ich immer ähnliche Programmiersprachen nutze, ich habe das Interesse daran, dass ich ähnliche Software nutze, auch vom Vendor her gesehen, damit ich immer mit den gleichen Support Teams auch arbeiten kann, also das Business Interesse ist primär Skaleneffekte beim EDM und hat um eine gewisse Einheit zu kriegen, um auch im Data Governance Bereich nicht überall eine neue Governance aufzusetzen zu müssen. (S.2)",Use Case,,,,,,,,,
9,Chief Data Officer,Wirtschaftsprüfung,Beratung,"[EDC] das ist natürlich für das Business noch viel spannender, weil da kommt ja auch irgendwann der End-User zum Schluss, wo eben schauen kann, was für Daten habe ich als Unternehmen, wie kann ich die nutzen, da kann ich dann mit Metadaten genau hinterlegen, wer darf was wie nutzen und genau das ist ja auch interessant, vor allem in einem grossen Unternehmen, weil wir haben so viele Daten, wenn man keinen guten Catalog hat, dann kann es gut und gerne passieren, dass man die gleichen Daten am Schluss 20 Mal hat, schlimmstenfalls bei uns renne ich dreimal zum Kunden und frage ihn dreimal nach dem gleichen Datensatz und genau das kann ich mit einem Catalog ja verhindern, habe dann auch wieder die Skaleneffekte, dass ich es einmal extrahiere und nicht fünfmal und beim EDC, was da natürlich dazukommt für die Data Governance Leute, die sind auch happy, wenn da die Attributes richtig hinterlegt sind und man hat dann Attribute Based Access Controls, wo genau definieren, nur mit diesem Attribut kannst du dann auch auf die Daten zugreifen, also von dem her gesehen ist es ein sehr wichtiges Thema (S.2)",Use Case,,,,,,,,,
9,Chief Data Officer,Wirtschaftsprüfung,Beratung,"[EDC - Business Seite] also es gibt eigentlich den zentralen Use Case beim Enterprise Data Catalog, also ich möchte den Business User enablen, die Daten im Unternehmen sinnvoll nutzen zu können. Ohne diesen EDC muss ein Business User teilweise riesen Aufwand betreiben, um zu verstehen, wenn ich jetzt Kunde A habe, wie viele Daten habe ich von dem, welche Daten habe ich von dem, woher kommen die Daten, sind das die richtigen Daten, all diese Themen sind enorm komplex, wenn ich jetzt als Business User einfach hingehe und keinen EDC habe. Mit dem EDC kann ich das im besten Falle auf einen Blick sehen, insofern ich natürlich über meine Attributes überhaupt die Rechte habe, um es zu sehen. Ansonsten sehe ich einfach, okay, wir haben Daten, dann steht da vielleicht noch dabei, um Zugriff zu erlangen, muss das und das erfüllt sein (S.3)",Use Case,Use Case: Business User auf Daten Suche,,,,,,,,
9,Chief Data Officer,Wirtschaftsprüfung,Beratung,"[EDC - Data Governance] die Governance Leute haben natürlich auch ihren Spass, wenn die genau wissen, okay, zu diesen Daten haben die Leute Zugriff mit den Attributen und wenn es dann mal darum geht, dass ein Regulator irgendwas wissen will, kann man auch schneller eine Antwort finden, wer jetzt Zugriff hat auf diese Daten und wer eben nicht (S.3)",Use Case,,,,,,,,,
9,Chief Data Officer,Wirtschaftsprüfung,Beratung,"[EDM - Skaleneffekte] da gibt es Skaleneffekte, ich kann mit wenigen Vendors zusammenarbeiten, habe einen gewissen Skaleneffekt, weil ich einfach Dänger dann habe, das geht vor allem auch bei der Cloud-Usage einfach darum, wenn ich mehr Cloud-Usage habe bei einem spezifischen Anwender, dann wird es in der Regel günstiger, einheitliche Architektur ermöglicht Zentralisierung von Support Teams, Zentralisierung von Development Teams, ich brauche nicht noch irgendeinen, der noch irgendeine fünfte oder hundertste Programmiersprache kann, sondern ich kann das so ein bisschen um die Wichtigsten zentralisieren (S. 4)",Use Case,,,,,,,,,
9,Chief Data Officer,Wirtschaftsprüfung,Beratung,"[Zielgruppe EDM/EDC] Es ist wirklich da wichtig, wo ich viele Daten habe, mit vielen Daten umgehen muss, vielleicht auch nicht unbedingt in der Produktion, in der Cloud-Produktion, da gibt es auch gewisse Benefits, was ein EDM, EDC mit sich bringen kann, aber da gibt es andere Themen, die viel mehr Benefits bringen, sondern wirklich, wenn ich Services habe, die vor allem auf Daten getrieben sind oder wenn ich Dienstleistungen erbringe, dann bietet es mir natürlich viel mehr Möglichkeiten, auch mit Erfahrungswerten, mit Daten, die ich halt über die Kunden habe, danach etwas anzustellen (S. 8)",Implementierungsgrund,,,,,,,,,
9,Chief Data Officer,Wirtschaftsprüfung,Beratung,"[UseCase AI] dann wirklich auf eine gute Datenarchitektur an, gutes Datenmanagement, gute Datenkataloge, dann kann ich deutlich besser auch mit AI arbeiten gehen und das unterschätzen aber auch viele Unternehmen und viele Unternehmen klagen im Moment einfach AI auf alles obendrauf und wundern sich, dass AI dann nicht den Benefit bringt, (S.8)","Use Case
","Use Case: AI 
",,,,,,,,
27,Data Steward,Bank,Externe Firma,"[EDC]  Yeah, I like to say, yeah, it is, of course, a way to see how data, everything is connected, where you're going to find a specific data. But it's also a dictionary so that you understand what data means. Because a lot of confusion happens in the companies because I say, oh, I have this data. But we mean totally different things. And then having that platform where definitions are agreed upon and signed off by somebody who owns that definition is really important, especially for companies that are very big. (S,4)",Funktionalität EDC,,,,,,,,,
27,Data Steward,Bank,Externe Firma,"[Collibra - Glossary - Workflow] only Collibra. But I would say it should be a feature of a data catalog. It should allow you to store your definitions and I believe ideally also to provide workflows so that your data definition process can happen, can be hosted in this platform. (S.5)","Use Case
","Use Case: Provide Workflow 
Use Case: Glossary",,,,,,,,
27,Data Steward,Bank,Externe Firma,"[Permission - Workflow] That person has to acknowledge that he or she is the owner. Then you register. And then you trigger a workflow in Collibra that is going to send an email to the person who owns the definition and the person who owns the definition presses the button saying, I accept (S. 5)",Use Case,Use Case: Data Ownership ,,,,,,,,
27,Data Steward,Bank,Externe Firma,"[EDC - KPIs - Rules]  Every office in the world has their own way of calculating that. And then when all these offices send their KPIs to the headquarters, how can you compare the performance of China with the performance of U.S. or whatever if the way of calculating is different, right? And sometimes it's not only that it's different but it's not transparent. And once we agree on that, we're going to make it official by registering it in the data catalog in Collibra. And we're going to make it official by having owners for these definitions. (S.6-7)",Funktionalität EDC,,,,,,,,,
27,Data Steward,Bank,Externe Firma,"[Fehlerreduktion - KPIs EDC]  you minimize errors because you know exactly when you have a report and you have that report, let's say, under governance, so transparent in Collibra, etc. You don't have doubts about, let's say, the numbers. And you also, having that transparent and owned by somebody reduces a lot of conflict between people, among people. So having the data catalog (S.7)",Funktionalität Collibra,,,,,,,,,
28,Data Architect,IT Services,Beratung,"[EDC] so with data catalogs, they come in as a tool to organize messy data warehouses, messy data lakes to help companies find their assets by utilizing or by using mostly the sort of like query logs (S.2)",Implementierungsgrund,,,,,,,,,
28,Data Architect,IT Services,Beratung,"[EDM] Now enterprise data models are something a little bit more interesting. They make a lot of sense to people like me, to people who understand the data, is we say like, hey, we start with a very clean structure that mirrors the business, and then we derive everything from there. (S.3)",Implementierungsgrund,,,,,,,,,
29,Geschäftsleitung,Collibra,EDM / EDC Anbieter,[Goal Collibra] there's still a lot of things that are very much the same in the sense that what we're trying to do is make it so that data in an organization is treated more like an asset rather than an exhaust. And that people turn the data into value through a data product lens to make a product with value from the data (S.3),Funktionalität Collibra,,,,,,,,,
29,Geschäftsleitung,Collibra,EDM / EDC Anbieter,"[Software Kategorie] Our software category is the data governance software category. we saw for the first time in our long history, Gartner confirmed our updated position, which is it's no longer about data governance alone. It's today about data and AI and data analytics governance, what we call unified governance.  (S.6-7)",Use Case,"Use Case: AI 
Use Case: Data Analytics ",,,,,,,,
29,Geschäftsleitung,Collibra,EDM / EDC Anbieter,"[Berechtigung für Datenmanagementtools] And then from big data came, where do we store all this big data? We got to put it in a data platform. We got to put it in a data lake. We got to put it in a data warehouse. Whatever name they gave, they sort of hit the same problem that they have with every data platform for decennial now, which is people put stuff in there. And then after a while, they don't even know what's in there anymore or what the quality of it is. So at that time, in the 2010s, the puberty phase of data management, they said, oh, let's solve that with a catalog. We will put a catalog over our data lake and the catalog will give you the transparency as in what is inside my data lake, what is inside my data platform. So that's when the catalog started to appear as naming in the industry. (S.8)",Funktionalität EDC,,,,,,,,,
29,Geschäftsleitung,Collibra,EDM / EDC Anbieter,"[UseCase Catalog] So if you're a catalog vendor and you take this position, my catalog is a window that shows you what's in my lake. You do that with a certain purpose, right? So let's say you're a business user and you're like, oh, I'm going to check in what's in my lake because I want to get access to this data to make my analysis, to draw my insight and make my decision. So the catalog gives you that window as in what lives in your lake, but it doesn't mean that you immediately have access (S:9)",Funktionalität EDC,,,,,,,,,
29,Geschäftsleitung,Collibra,EDM / EDC Anbieter,"[Funktionalität Catalog] It's like when you buy a book online, you see the description of the book and you see the title and the author and the reviews and everything, but you don't have the book until you buy it. With the catalog on the data lake or on the data platform or whatever, it's the same game. You see that there's data in there about customers, but then you have to request access to it (S. 9)",Funktionalität EDC,,,,,,,,,
29,Geschäftsleitung,Collibra,EDM / EDC Anbieter,"[Verschiedene Implementationsarten von Catalogs - technical metadata repository initiative] 
But they might turn this catalog initiative into what I would refer to as a technical metadata repository initiative. And the way that you can assess that is by opening the catalog and seeing what's inside. And I'll give you another metaphor there. So let's say that I go to IKEA, and I want to buy a bed and a bookcase. And so I go in the catalog of IKEA, but the catalog of IKEA only shows me planks and nuts and bolts. So yes, bookcases are composed out of planks and nuts and bolts. And I know that I can take the nuts and bolts and the planks and put them together in a bookcase. But the catalog is only showing me the books, the nuts and the bolts and the planks. That would be an example of a catalog initiative which is implemented as a technical metadata repository initiative. And that means that this initiative probably supports needs of only technical people. And that might be fine for a time, but again, that initiative will hit that wall if they don't start planning to include business involvement at some point in time. Now, that's one interpretation of a catalog initiative. (S.11)",Use Case,Use Case: Technical Metadata repository initiative,,,,,,,,
29,Geschäftsleitung,Collibra,EDM / EDC Anbieter,"I'll give you a second interpretation of a catalog initiative. And that is where you have to seethe catalog not as a technical metadata repository initiative, but maybe more as a data marketplace initiative. So now I'm using the same metaphor, the IKEA catalog. I go shop for books, sorry, bookcases and beds. And I'm going to find in the IKEA catalog bookcases and beds and kitchens. And when I buy it, I get a box with nuts and bolts and planks and instructions to put it together. So essentially what I'm saying is that if I implement the catalog as a data marketplace, then the contents of my catalog might contain similar technical metadata, but it will also contain data sets and data products like dashboards and AI models, for example. So it will be a slightly different initiative, but that data marketplace initiative, so same technology, right? Both of those are catalog initiatives. (S. 12) ",Use Case,Use Case: Data Marketplace,,,,,,,,
29,Geschäftsleitung,Collibra,EDM / EDC Anbieter,"And now we will talk about the legal compliance or data privacy persona. So since 2016, GDPR came into the market. I'm sure you're familiar with it. And one of the requirements that GDPR imposes on organizations, large and small, around the world, is to set up a process registry. And aprocess registry, Finn, is nothing more than what business processes does the organization have. Like, you know, making customers and sending them products and invoicing them. These are examples of business processes. And for every business process, what data does it produce or consume?
And for that data production or consumption, what privacy impact assessments have happened, for example. In other words, the process register, which is GDPR-speak, in my view, for catalog, is nothing but a list of all the data usages in the organization. Which means that you need the data sets and who has requested access to them and for what purpose. Which is something that you would be doing inside a data marketplace. You're shopping for data. Shopping for data is a broad data usage in GDPR-speak.(S:12)",Use Case,Use Case: Process Registry,,,,,,,,
29,Geschäftsleitung,Collibra,EDM / EDC Anbieter,"the platform players, the hyperscalers, started from the infrastructure up, from file system and server in the cloud, going upwards also into the data space, offering their own data warehouses and data management software And as a consequence, these platforms also needed to add a catalog capability to their data platform. So to your point about budgets that you mentioned earlier, if you're a CIO in an organization today, it's probably because of AI that for the first time you start to think about things like data governance and catalogs. Today, this is on their agenda, in my opinion, predominantly driven by the AI platform shift (S.12-13)",Use Case,Use Case: Agent AI Konzepte,,,,,,,,
29,Geschäftsleitung,Collibra,EDM / EDC Anbieter,"[Abgrenzung des Begriffs Catalog] And if you then don't have the awareness of those different types of catalog initiatives that I just highlighted to you, and there's a few others too, and you're just saying I can solve all of this in my hyperscaler catalog, then you are making a big mistake because that hyperscaler catalog is honestly like an instrument used by the hyperscalers to give a viewpoint on the data within their data warehouse, for example, within Amazon's Redshift or within Google's BigQuery. It is not a catalog typically that shows you what data you have in your organization. It is not a catalog that is going to serve as a process registry. It is not a catalog that will function even as a technical metadata repository. It's only going to give you a way to operate data within Microsoft or within Google, for example (S.13)",Use Case,Use Case: Process Registry,,,,,,,,
29,Geschäftsleitung,Collibra,EDM / EDC Anbieter,"So they're saying, we're centralizing our data work. Then you will have one way of implementing that catalog initiative and making it successful (S.15)",Funktionalität EDC,,,,,,,,,
30,Head of Community,IT Services,EDM / EDC Anbieter,"[Data Governance] Data Governance. Also im Prinzip dafür zu sorgen, dass du Daten ordentlich bewirtschaftest und irgendwie standardisiert, strukturiert im Unternehmen anfasst. Dazu musst du Regeln festlegen. Und ich glaube, erst mal ein Datenmodell hilft dabei, zu sagen, über welche Daten ich rede. Und ein Datenkatalog hilft dann dabei, auf sowas wie Ownership festzulegen, eine Definition, die über das ganze Unternehmen einheitlich sein sollte, irgendwo sicherzustellen (S.4)",Funktionalität EDM und EDC,,,,,,,,,
30,Head of Community,IT Services,EDM / EDC Anbieter,"[EDC & EDM] Dazu musst du Regeln festlegen. Und ich glaube, erst mal ein Datenmodell hilft dabei, zu sagen, über welche Daten ich rede. Und ein Datenkatalog hilft dann dabei, auf sowas wie Ownership festzulegen, eine Definition, die über das ganze Unternehmen einheitlich sein sollte, irgendwo sicherzustellen. Ich habe eine Data Foundation, auf die dann der Rest des Unternehmens, die Geschäftsprozesse, aber auch das Analytics- oder Data Science Team zugreifen kann. Das passiert unterstützt durch ein Datenmodell, aber insbesondere dann auch durch ein Datenkatalog, wo ich die Metadaten dokumentieren kann und festlegen kann. Das heißt, das ist eine Hilfe, Governance erst mal zu definieren und auch durchzusetzen (S.4)",Funktionalität EDM und EDC,,,,,,,,,
30,Head of Community,IT Services,EDM / EDC Anbieter,"[Data Marketplace] Ich will ja nicht nur, dass die Daten in Geschäftsprozessen genutzt werden, sondern möchte die auch verfügbar und nutzbar machen für meine Analytics Teams. Und da hilft ein Datenkatalog, vielleicht eher sogar noch ein Data Marketplace, aber einfach, um so explorativ zu gucken, welche Daten habe ich denn und wie kann ich die eigentlich in meinen Data Science, Analytics Projekten sinnstiftend einsetzen (S.4)",Use Case,Use Case: Data Marketplace,,,,,,,,
30,Head of Community,IT Services,EDM / EDC Anbieter,"[Reusability] was du ja machst ist ja Effizienz sicherstellen, du möchtest ja Daten, irgendwie dieses Fair machen, kennst du wahrscheinlich Findable, Accessible, Interoperable, Reusable und gerade dieses R, also die Reusability, sollte eigentlich mit einem Datenkatalog steigen. Was heißt das? Ich dokumentiere die Daten so und mache die so verfügbar, dass ich beim ersten Data Science Use Case muss ich natürlich zum Datenkatalog gehen und sage, hey, guck mal, wie kann ich die nutzen, damit ich die nutzbar habe (S.5)",Funktionalität EDM und EDC,,,,,,,,,
30,Head of Community,IT Services,EDM / EDC Anbieter,"[Findability] Das andere ist, dass ich, genau, also Reusability und das andere ist das Thema, also dieses R von FAIR und das andere ist das F von FAIR, die Findability. Und jetzt möchtest du, dass die Daten sofort verfügbar und auffindbar sind. Das heißt, ich kann die eigentlich zentral einsehen, vielleicht nicht direkt nutzen, hoffentlich ist da noch so ein Freigabeprozess, dass ich durchaus sicherstelle, dass nur der, der es auch wirklich wissen sollte, dann darauf zugreifen kann. Also es ist dann auch noch Governance und es ist viel, viel schneller, als es vorher war (S:6)",Funktionalität EDM und EDC,,,,,,,,,
30,Head of Community,IT Services,EDM / EDC Anbieter,"Deswegen Karten, Daten-Katalog, Zeitersparnis, das eine. Und das andere ist eben diese Reusability, also im Prinzip die Skalierung der Daten. (S.6)",Funktionalität EDM und EDC,,,,,,,,,
30,Head of Community,IT Services,EDM / EDC Anbieter,"ich meine, Datenmodell ist ja erstmal nur eine Beschreibung, Dokumentation und von den Daten, die in einem Unternehmen verfügbar sind. Und der Datenkatalog, wenn du den als Tool siehst, der hat ja erstmal das Datenmodell in sich drin und gibt dann ja zusätzlich noch Informationen, also Metadaten über die Daten. (S.6)",Funktionalität EDM und EDC,,,,,,,,,
30,Head of Community,IT Services,EDM / EDC Anbieter,"[Catalog] Und der Datenkatalog macht genau diese Informationen einfacher zugänglich und im Zugriff, plus der Datenkatalog ermöglicht ja zusätzlich dann eben noch diese Suchfunktion und ähnliches. Ansonsten guckst du auf so ein Modellbild, so ein Architekturbild und musst dir dann deine Daten selber aussuchen, wenn die überhaupt dokumentiert sind. Von daher ist für mich eigentlich Datamodel ist so ein Konzeptschritt hin, dass ich einen Datenkatalog aufbauen kann (S.6)",Funktionalität EDC,,,,,,,,,
30,Head of Community,IT Services,EDM / EDC Anbieter,"[Dokumentation] Also das Wichtigste ist, also es ist ja ein Dokumentationstool und Risiko Nummer eins ist bei allen Dokumentationen, dass du die Daten ab und zu erhalten musst. Also alles, was da drinsteht, muss gepflegt werden. (S.9)",Use Case,Use Case: Dokumentationstool,,,,,,,,
31,Professor,IT Management,Univesität,"[Potenzielle Auswirkungen] weil umso besser die Datengrundlage ist und vorliegt, umso besser kannst du auch Forecastings machen, Belegungspläne machen. Ressourcen effektiv ausnutzen, sodass Wartezeiten verringert werden, hat riesige Implikationen. Wirtschaftliche Unternehmen, je nach Use Case natürlich auch. Ich glaube allein, dass ich die Accuracy in meinem Reporting besser hinbekomme. Oder wenn ich Daten am Ende irgendwie End-zu-Ende verfügbar habe, dann kann ich ja nicht nur statisch einfach nur reporten, also Vergangenheitsanalysen, sondern ich kann auch Simulationen machen und dann auch besser forecasten, wie ich meine Produktionslandschaft beispielsweise aufstellen soll oder you name it. (S.3)",Use Case,,,,,,,,,
31,Professor,IT Management,Univesität,"[Potenzielle Auswirkungen] Und am Ende geht dir halt unglaublich viel Potenzial mit AI, Generative AI, Advantage AI und anderen Aspekten verloren, weil du Daten nicht effektiv nutzen kannst. Weil wir wissen ja alle, diese Systeme lernen von den historischen Daten, die man hat. Und wenn die Datenqualität schlecht ist, dann sind auch die Use Cases und die Modelle, die daraus entstehen, schlecht. (S.4)",Use Case,(Cost of Doing Nothing),,,,,,,,
31,Professor,IT Management,Univesität,"[Wichtigkeit Datenqualität für AI] Und wenn du AI dann wirklich, also diese Agent-AI-Konzepte nutzen möchtest, dass du autonome Agenten innerhalb deines Unternehmens hast, die zwischen Systemen Daten austauschen und dann noch mehr Automatisierungspotenzial heben, dann brauchst du das auch. Und ohne Datenqualität als Basis geht beides nicht (S.6)",Use Case,Use Case: Agent AI Konzepte,,,,,,,,
32,Professor,Information Systems,Univesität,"[EDC] Für mich ist ein Data Catalog im weitesten Sinne ein One-Stop-Shop für Data. Es gibt ein Unified Interface und da kann ich dann irgendwie auf die unterschiedlichen Data Assets, die ein Unternehmen hat, zugreifen und auch die dann irgendwie managebar machen. In den einzelnen Data Assets ist Personal Identifiable Data und so Geschichten kann man eigentlich über ein Data Catalog relativ gut abbilden, in meiner Meinung. (S.1)",Use Case,Use Case: One Stop Shop für Daten,,,,,,,,
32,Professor,Information Systems,Univesität,"[EDM] Für mich ein Enterprise Data Model ist dann eher eine Ebene tiefer. Da geht es dann darum, in meinen Augen mal zu definieren, welche Daten wollen wir eigentlich erheben zu was, zu welchem Zweck, in welcher Tiefe. Was sind eigentlich die ganzen Datenpunkte, die wir haben? (S.1)",Funktionalität EDM,,,,,,,,,
32,Professor,Information Systems,Univesität,"[EDM -Regeln] Solche Geschichten wären dann eigentlich für mich Teil von so einem Enterprise Data Model, dass man dort die relevanten Data Assets dann wirklich systematisch mal modelliert. Was nehmen wir dazu auf?  Wie genau? Und so weiter. Und dann stehen auch die ganzen Datenpunkte zusammen in Abhängigkeit. (S.1-2)",Funktionalität EDM,,,,,,,,,
32,Professor,Information Systems,Univesität,"Und wie kann ich dann diese Data Product umsetzen? Die kann ich dann irgendwie in einem Data Catalog abbilden und um dann diese Data Product dann auch sinnvoll machen zu können, managen zu können, dann brauche ich auch irgendwann mal ein Data Model, mit dem ich dann genau definiere, was kommt da eigentlich rein und was nicht und wie soll das aussehen. Das ist eigentlich für mich der größte Mindset Shift für Unternehmen (S.3)",Funktionalität EDM und EDC,,,,,,,,,
32,Professor,Information Systems,Univesität,"[EDC] Also die Unternehmen, die ich kenne, die besonders datengetrieben sind, die wollen über so ein Data-Catalog irgendwie, was die sagen, so eine Demokratisation auf Data bringen.  Schau mal, hier ist ein Unified Interface und da ist erstmal der Default, du hast Zugriff auf alle Daten. Es sei denn, es gibt irgendwelche Restrictions in puncto Compliance (S.3)",Funktionalität EDC,,,,,,,,,
,,,,,9,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,